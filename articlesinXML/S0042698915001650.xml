<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/article/pii/S0042698915001650</prism:url><dc:identifier>doi:10.1016/j.visres.2015.05.001</dc:identifier><eid>1-s2.0-S0042698915001650</eid><prism:doi>10.1016/j.visres.2015.05.001</prism:doi><pii>S0042-6989(15)00165-0</pii><dc:title>Facilitatory mechanisms of specular highlights in the perception of depth </dc:title><prism:publicationName>Vision Research</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>00426989</prism:issn><prism:volume>115</prism:volume><prism:startingPage>188</prism:startingPage><prism:endingPage>198</prism:endingPage><prism:pageRange>188-198</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2015-10-31</prism:coverDate><prism:coverDisplayDate>October 2015</prism:coverDisplayDate><prism:copyright>Copyright © 2015 Elsevier Ltd. All rights reserved.</prism:copyright><prism:publisher>Elsevier Ltd.</prism:publisher><prism:issueName>Perception of Material Properties (Part II)</prism:issueName><dc:creator>Sakai, Ko</dc:creator><dc:creator>Meiji, Ryoko</dc:creator><dc:creator>Abe, Tetsuya</dc:creator><dc:description>
               Abstract
               
                  We investigated whether specular highlights facilitate the perception of shape from shading in a search paradigm and how highlights interact with shading to facilitate this perception. Our results indicated that stimuli containing highlights led to shorter searching time with the dependence on the light source direction (top lights make searching faster), suggesting that highlights indeed facilitate shape-from-shading processing. To examine how highlight processing interacts with shading processing, we tested unnatural stimuli for which the lighting directions for shading and highlights were inconsistent. The results indicated that unnatural highlights (bright spots) placed in a direction inconsistent with the shading either decrease or do not alter searching time. This suggests that highlights may facilitate, and not suppress, shading processing. With more physically plausible highlights generated from image-based lighting, we also observed facilitation with consistent highlights, but no change with inconsistent highlights. Finally, we examined whether highlights indeed work to facilitate depth perception in a discrimination task. The results showed that correct discrimination of depth increases when highlights are added to shading even when their lighting directions are inconsistent. These results indicate that specular highlights facilitate shading processing, and do not suppress it even when the highlights are placed in a direction inconsistent with shading. The results also elucidate the lighting constraints of the visual system.
               
            </dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>true</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType>ElsevierBranded</openaccessSponsorType><openaccessUserLicense>http://www.elsevier.com/open-access/userlicense/1.0/</openaccessUserLicense><dcterms:subject>Shading</dcterms:subject><dcterms:subject>Pop-out</dcterms:subject><dcterms:subject>Specular highlights</dcterms:subject><dcterms:subject>Search paradigm</dcterms:subject><dcterms:subject>Depth discrimination</dcterms:subject><link href="https://api.elsevier.com/content/article/pii/S0042698915001650" rel="self"/><link href="https://www.sciencedirect.com/science/article/pii/S0042698915001650" rel="scidir"/></coredata><objects><object ref="mmc5" category="thumbnail" type="IMAGE-MMC-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="166" height="164" size="31215">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc5.sml?httpAccept=%2A%2F%2A</object><object ref="mmc4" category="thumbnail" type="IMAGE-MMC-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="167" height="164" size="29072">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc4.sml?httpAccept=%2A%2F%2A</object><object ref="mmc3" category="thumbnail" type="IMAGE-MMC-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="167" height="164" size="27241">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc3.sml?httpAccept=%2A%2F%2A</object><object ref="mmc2" category="thumbnail" type="IMAGE-MMC-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="166" height="163" size="24964">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc2.sml?httpAccept=%2A%2F%2A</object><object ref="mmc1" category="thumbnail" type="IMAGE-MMC-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="173" height="163" size="13717">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc1.sml?httpAccept=%2A%2F%2A</object><object ref="mmc5" category="standard" type="IMAGE-MMC-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="176" height="173" size="22317">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc5.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc4" category="standard" type="IMAGE-MMC-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="176" height="173" size="22735">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc4.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc3" category="standard" type="IMAGE-MMC-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="176" height="173" size="23879">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc3.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc2" category="standard" type="IMAGE-MMC-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="168" height="165" size="21438">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc2.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc1" category="standard" type="IMAGE-MMC-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="169" height="160" size="13645">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc1.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc5" category="standard" type="VIDEO" multimediatype="MPEG-4 movie" mimetype="video/mp4" size="2627824">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc5.mp4?httpAccept=%2A%2F%2A</object><object ref="mmc4" category="standard" type="VIDEO" multimediatype="MPEG-4 movie" mimetype="video/mp4" size="2655085">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc4.mp4?httpAccept=%2A%2F%2A</object><object ref="mmc3" category="standard" type="VIDEO" multimediatype="MPEG-4 movie" mimetype="video/mp4" size="2920107">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc3.mp4?httpAccept=%2A%2F%2A</object><object ref="mmc2" category="standard" type="VIDEO" multimediatype="MPEG-4 movie" mimetype="video/mp4" size="6981284">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc2.mp4?httpAccept=%2A%2F%2A</object><object ref="mmc1" category="standard" type="VIDEO" multimediatype="MPEG-4 movie" mimetype="video/mp4" size="9122812">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc1.mp4?httpAccept=%2A%2F%2A</object><object ref="gr1" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2933" height="1964" size="219114">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr1_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="fx2" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1644" height="1190" size="150356">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx2_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="fx1" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1578" height="1453" size="165452">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx1_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1673" height="1016" size="118039">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr9_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1672" height="2344" size="257811">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr8_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1674" height="1105" size="164855">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr7_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2760" height="2048" size="205304">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr6_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1579" height="1949" size="202382">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr5_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1673" height="1476" size="212034">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr4_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1378" height="964" size="80673">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr3_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2166" height="1298" size="206474">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr2_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc5" category="standard" type="VIDEO-FLASH" multimediatype="Flash Video file" mimetype="video/x-flv" size="2967868">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc5.flv?httpAccept=%2A%2F%2A</object><object ref="mmc4" category="standard" type="VIDEO-FLASH" multimediatype="Flash Video file" mimetype="video/x-flv" size="2965062">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc4.flv?httpAccept=%2A%2F%2A</object><object ref="mmc3" category="standard" type="VIDEO-FLASH" multimediatype="Flash Video file" mimetype="video/x-flv" size="2950586">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc3.flv?httpAccept=%2A%2F%2A</object><object ref="mmc2" category="standard" type="VIDEO-FLASH" multimediatype="Flash Video file" mimetype="video/x-flv" size="6521228">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc2.flv?httpAccept=%2A%2F%2A</object><object ref="mmc1" category="standard" type="VIDEO-FLASH" multimediatype="Flash Video file" mimetype="video/x-flv" size="8562597">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc1.flv?httpAccept=%2A%2F%2A</object><object ref="gr1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="662" height="443" size="37325">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr1.jpg?httpAccept=%2A%2F%2A</object><object ref="fx2" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="371" height="269" size="21999">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx2.jpg?httpAccept=%2A%2F%2A</object><object ref="fx1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="356" height="328" size="25421">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx1.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="378" height="230" size="16157">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr9.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="377" height="529" size="42479">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr8.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="378" height="250" size="25207">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr7.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="623" height="462" size="40740">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr6.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="356" height="439" size="25716">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr5.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="378" height="333" size="31057">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr4.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="311" height="218" size="11925">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr3.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="489" height="293" size="30261">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr2.jpg?httpAccept=%2A%2F%2A</object><object ref="gr1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="147" size="7595">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr1.sml?httpAccept=%2A%2F%2A</object><object ref="fx2" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="159" size="7707">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx2.sml?httpAccept=%2A%2F%2A</object><object ref="fx1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="178" height="164" size="7116">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-fx1.sml?httpAccept=%2A%2F%2A</object><object ref="gr9" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="133" size="4245">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr9.sml?httpAccept=%2A%2F%2A</object><object ref="gr8" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="117" height="164" size="8858">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr8.sml?httpAccept=%2A%2F%2A</object><object ref="gr7" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="145" size="8559">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr7.sml?httpAccept=%2A%2F%2A</object><object ref="gr6" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="163" size="15979">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr6.sml?httpAccept=%2A%2F%2A</object><object ref="gr5" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="133" height="164" size="4743">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr5.sml?httpAccept=%2A%2F%2A</object><object ref="gr4" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="186" height="164" size="8454">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr4.sml?httpAccept=%2A%2F%2A</object><object ref="gr3" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="153" size="5307">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr3.sml?httpAccept=%2A%2F%2A</object><object ref="gr2" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="131" size="6928">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-gr2.sml?httpAccept=%2A%2F%2A</object><object ref="mmc6" category="standard" type="APPLICATION" multimediatype="Acrobat PDF file" mimetype="application/pdf" size="812604">https://api.elsevier.com/content/object/eid/1-s2.0-S0042698915001650-mmc6.pdf?httpAccept=%2A%2F%2A</object></objects><scopus-id>84944176524</scopus-id><scopus-eid>2-s2.0-84944176524</scopus-eid><pubmed-id>25982713</pubmed-id><link href="https://api.elsevier.com/content/abstract/scopus_id/84944176524" rel="abstract"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://null/schema/dtds/document/fulltext/xcr/xocs-article.xsd">
   <xocs:meta>
      <xocs:content-family>serial</xocs:content-family>
      <xocs:content-type>JL</xocs:content-type>
      <xocs:cid>271122</xocs:cid>
      <xocs:ssids>
         <xocs:ssid type="alllist">291210</xocs:ssid>
         <xocs:ssid type="subj">291684</xocs:ssid>
         <xocs:ssid type="subj">291736</xocs:ssid>
         <xocs:ssid type="content">31</xocs:ssid>
      </xocs:ssids>
      <xocs:srctitle>Vision Research</xocs:srctitle>
      <xocs:normalized-srctitle>VISIONRESEARCH</xocs:normalized-srctitle>
      <xocs:orig-load-date yyyymmdd="20150514">2015-05-14</xocs:orig-load-date>
      <xocs:available-online-date yyyymmdd="20150514">2015-05-14</xocs:available-online-date>
      <xocs:vor-load-date yyyymmdd="20151014">2015-10-14</xocs:vor-load-date>
      <xocs:vor-available-online-date yyyymmdd="20151014">2015-10-14</xocs:vor-available-online-date>
      <xocs:ew-transaction-id>2015-10-14T17:51:43</xocs:ew-transaction-id>
      <xocs:eid>1-s2.0-S0042698915001650</xocs:eid>
      <xocs:pii-formatted>S0042-6989(15)00165-0</xocs:pii-formatted>
      <xocs:pii-unformatted>S0042698915001650</xocs:pii-unformatted>
      <xocs:doi>10.1016/j.visres.2015.05.001</xocs:doi>
      <xocs:item-stage>S300</xocs:item-stage>
      <xocs:item-version-number>S300.1</xocs:item-version-number>
      <xocs:item-weight>FULL-TEXT</xocs:item-weight>
      <xocs:hub-eid>1-s2.0-S0042698915X00149</xocs:hub-eid>
      <xocs:timestamp yyyymmdd="20170331">2017-03-31T22:14:51.790991-04:00</xocs:timestamp>
      <xocs:dco>0</xocs:dco>
      <xocs:tomb>0</xocs:tomb>
      <xocs:date-search-begin>20151001</xocs:date-search-begin>
      <xocs:date-search-end>20151031</xocs:date-search-end>
      <xocs:year-nav>2015</xocs:year-nav>
      <xocs:indexeddate epoch="1431572811">2015-05-14T03:06:51.410657Z</xocs:indexeddate>
      <xocs:articleinfo>articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref</xocs:articleinfo>
      <xocs:issns>
         <xocs:issn-primary-formatted>0042-6989</xocs:issn-primary-formatted>
         <xocs:issn-primary-unformatted>00426989</xocs:issn-primary-unformatted>
      </xocs:issns>
      <xocs:crossmark is-crossmark="1">true</xocs:crossmark>
      <xocs:vol-first>115</xocs:vol-first>
      <xocs:volume-list>
         <xocs:volume>115</xocs:volume>
      </xocs:volume-list>
      <xocs:suppl>PB</xocs:suppl>
      <xocs:vol-iss-suppl-text>Volume 115, Part B</xocs:vol-iss-suppl-text>
      <xocs:sort-order>5</xocs:sort-order>
      <xocs:first-fp>188</xocs:first-fp>
      <xocs:last-lp>198</xocs:last-lp>
      <xocs:pages>
         <xocs:first-page>188</xocs:first-page>
         <xocs:last-page>198</xocs:last-page>
      </xocs:pages>
      <xocs:cover-date-orig>
         <xocs:start-date>201510</xocs:start-date>
      </xocs:cover-date-orig>
      <xocs:cover-date-text>October 2015</xocs:cover-date-text>
      <xocs:cover-date-start>2015-10-01</xocs:cover-date-start>
      <xocs:cover-date-end>2015-10-31</xocs:cover-date-end>
      <xocs:cover-date-year>2015</xocs:cover-date-year>
      <xocs:title-editors-groups>
         <xocs:title-editors-group>
            <ce:title id="tt005">Perception of Material Properties (Part II)</ce:title>
            <ce:editors>
               <ce:author-group id="aa0020">
                  <ce:author id="aa005">
                     <ce:given-name>Roland W</ce:given-name>
                     <ce:surname>Fleming</ce:surname>
                  </ce:author>
                  <ce:author id="aa0010">
                     <ce:given-name>Shin'ya</ce:given-name>
                     <ce:surname>Nishida</ce:surname>
                  </ce:author>
                  <ce:author id="aa0015">
                     <ce:given-name>Karl R</ce:given-name>
                     <ce:surname>Gegenfurtner</ce:surname>
                  </ce:author>
               </ce:author-group>
            </ce:editors>
         </xocs:title-editors-group>
      </xocs:title-editors-groups>
      <xocs:document-type>article</xocs:document-type>
      <xocs:document-subtype>fla</xocs:document-subtype>
      <xocs:copyright-line>Copyright © 2015 Elsevier Ltd. All rights reserved.</xocs:copyright-line>
      <xocs:normalized-article-title>FACILITATORYMECHANISMSSPECULARHIGHLIGHTSINPERCEPTIONDEPTH</xocs:normalized-article-title>
      <xocs:normalized-first-auth-surname>SAKAI</xocs:normalized-first-auth-surname>
      <xocs:normalized-first-auth-initial>K</xocs:normalized-first-auth-initial>
      <xocs:item-toc>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>1</xocs:item-toc-label>
            <xocs:item-toc-section-title>Introduction</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>2</xocs:item-toc-label>
            <xocs:item-toc-section-title>Experiment 1</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>2.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Method</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>2.1.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Stimuli</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>2.1.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Procedures and participants</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>2.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Results</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>2.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Discussion</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>3</xocs:item-toc-label>
            <xocs:item-toc-section-title>Experiment 2</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>3.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Method</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>3.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Results</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>3.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Discussion</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>4</xocs:item-toc-label>
            <xocs:item-toc-section-title>Experiment 3</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>4.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Method</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>4.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Results</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>4.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Discussion</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>5</xocs:item-toc-label>
            <xocs:item-toc-section-title>Experiment 4</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Method</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Stimuli</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Procedure and participants</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Results</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Discussion</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>6</xocs:item-toc-label>
            <xocs:item-toc-section-title>General discussion</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>7</xocs:item-toc-label>
            <xocs:item-toc-section-title>Conclusion</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:acknowledgment">
            <xocs:item-toc-section-title>Acknowledgments</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:appendices">
            <xocs:item-toc-label>Appendix A</xocs:item-toc-label>
            <xocs:item-toc-section-title>Supplementary data</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:bibliography">
            <xocs:item-toc-section-title>References</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
      </xocs:item-toc>
      <xocs:references>
         <xocs:ref-info refid="h0005">
            <xocs:ref-normalized-surname>ADELSON</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2008</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>E</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0010">
            <xocs:ref-normalized-surname>AKS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1992</xocs:ref-pub-year>
            <xocs:ref-first-fp>63</xocs:ref-first-fp>
            <xocs:ref-last-lp>74</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>D</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0015">
            <xocs:ref-normalized-surname>ANDERSON</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2009</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>17</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>B</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0020">
            <xocs:ref-normalized-surname>BULTHOFF</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1991</xocs:ref-pub-year>
            <xocs:ref-first-fp>305</xocs:ref-first-fp>
            <xocs:ref-last-lp>330</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>H</xocs:ref-normalized-initial>
            <xocs:ref-normalized-srctitle>COMPUTATIONALMODELSVISUALPROCESSING</xocs:ref-normalized-srctitle>
            <xocs:ref-normalized-article-title>SHAPEXPSYCHOPHYSICSCOMPUTATION</xocs:ref-normalized-article-title>
         </xocs:ref-info>
         <xocs:ref-info refid="h0025">
            <xocs:ref-normalized-surname>CHACON</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2004</xocs:ref-pub-year>
            <xocs:ref-first-fp>1499</xocs:ref-first-fp>
            <xocs:ref-last-lp>1509</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>J</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0030">
            <xocs:ref-normalized-surname>CHAMPION</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2007</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>10</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>R</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0035">
            <xocs:ref-normalized-surname>CHEN</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2006</xocs:ref-pub-year>
            <xocs:ref-first-fp>1825</xocs:ref-first-fp>
            <xocs:ref-last-lp>1832</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>T</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0040">
            <xocs:ref-normalized-surname>FLEMING</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2004</xocs:ref-pub-year>
            <xocs:ref-first-fp>798</xocs:ref-first-fp>
            <xocs:ref-last-lp>820</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>R</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0045">
            <xocs:ref-normalized-surname>KAWABE</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2004</xocs:ref-pub-year>
            <xocs:ref-first-fp>601</xocs:ref-first-fp>
            <xocs:ref-last-lp>614</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>T</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0050">
            <xocs:ref-normalized-surname>KHANG</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2007</xocs:ref-pub-year>
            <xocs:ref-first-fp>1191</xocs:ref-first-fp>
            <xocs:ref-last-lp>1213</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>B</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0055">
            <xocs:ref-normalized-surname>KLEFFNER</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1992</xocs:ref-pub-year>
            <xocs:ref-first-fp>18</xocs:ref-first-fp>
            <xocs:ref-last-lp>36</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>D</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0060"/>
         <xocs:ref-info refid="h0065">
            <xocs:ref-normalized-surname>MARLOW</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2011</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>12</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>P</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0070">
            <xocs:ref-normalized-surname>MOTOYOSHI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2007</xocs:ref-pub-year>
            <xocs:ref-first-fp>206</xocs:ref-first-fp>
            <xocs:ref-last-lp>209</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>I</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0075">
            <xocs:ref-normalized-surname>NEFS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2008</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>16</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>H</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0080">
            <xocs:ref-normalized-surname>NEFS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2006</xocs:ref-pub-year>
            <xocs:ref-first-fp>297</xocs:ref-first-fp>
            <xocs:ref-last-lp>316</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>H</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0085">
            <xocs:ref-normalized-surname>NISHIO</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2012</xocs:ref-pub-year>
            <xocs:ref-first-fp>10780</xocs:ref-first-fp>
            <xocs:ref-last-lp>10793</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>A</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0090">
            <xocs:ref-normalized-surname>NORMAN</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2004</xocs:ref-pub-year>
            <xocs:ref-first-fp>565</xocs:ref-first-fp>
            <xocs:ref-last-lp>570</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>J</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0095">
            <xocs:ref-normalized-surname>PHILLIPS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1997</xocs:ref-pub-year>
            <xocs:ref-first-fp>1481</xocs:ref-first-fp>
            <xocs:ref-last-lp>1492</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>F</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0100">
            <xocs:ref-normalized-surname>RAMACHANDRAN</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1988</xocs:ref-pub-year>
            <xocs:ref-first-fp>163</xocs:ref-first-fp>
            <xocs:ref-last-lp>166</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>V</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0105">
            <xocs:ref-normalized-surname>SAKAI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2006</xocs:ref-pub-year>
            <xocs:ref-first-fp>1805</xocs:ref-first-fp>
            <xocs:ref-last-lp>1813</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>K</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0110">
            <xocs:ref-normalized-surname>SUN</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1998</xocs:ref-pub-year>
            <xocs:ref-first-fp>183</xocs:ref-first-fp>
            <xocs:ref-last-lp>184</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>J</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0115">
            <xocs:ref-normalized-surname>WARD</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1994</xocs:ref-pub-year>
            <xocs:ref-first-fp>265</xocs:ref-first-fp>
            <xocs:ref-last-lp>272</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>G</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="h0120">
            <xocs:ref-normalized-surname>WIJNTJES</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2012</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>11</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>M</xocs:ref-normalized-initial>
         </xocs:ref-info>
      </xocs:references>
      <xocs:refkeys>
         <xocs:refkey3>SAKAIX2015X188</xocs:refkey3>
         <xocs:refkey4lp>SAKAIX2015X188X198</xocs:refkey4lp>
         <xocs:refkey4ai>SAKAIX2015X188XK</xocs:refkey4ai>
         <xocs:refkey5>SAKAIX2015X188X198XK</xocs:refkey5>
      </xocs:refkeys>
      <xocs:open-access>
         <xocs:oa-article-status is-open-access="1" is-open-archive="1">Full</xocs:oa-article-status>
         <xocs:oa-access-effective-date>2017-04-01T00:30:27Z</xocs:oa-access-effective-date>
         <xocs:oa-access-inherited-from winid="http://vtw.elsevier.com/content/oaw/00426989_P1Y6M_ESBranded" wintype="OpenArchive">OA-Window</xocs:oa-access-inherited-from>
         <xocs:oa-sponsor>
            <xocs:oa-sponsor-type>ElsevierBranded</xocs:oa-sponsor-type>
         </xocs:oa-sponsor>
         <xocs:oa-user-license>http://www.elsevier.com/open-access/userlicense/1.0/</xocs:oa-user-license>
      </xocs:open-access>
      <xocs:self-archiving>
         <xocs:sa-embargo-status>UnderEmbargo</xocs:sa-embargo-status>
         <xocs:sa-user-license>http://creativecommons.org/licenses/by-nc-nd/4.0/</xocs:sa-user-license>
         <xocs:sa-start-date>2016-10-14T00:00:00Z</xocs:sa-start-date>
      </xocs:self-archiving>
      <xocs:attachment-metadata-doc>
         <xocs:attachment-set-type>item</xocs:attachment-set-type>
         <xocs:pii-formatted>S0042-6989(15)00165-0</xocs:pii-formatted>
         <xocs:pii-unformatted>S0042698915001650</xocs:pii-unformatted>
         <xocs:eid>1-s2.0-S0042698915001650</xocs:eid>
         <xocs:doi>10.1016/j.visres.2015.05.001</xocs:doi>
         <xocs:cid>271122</xocs:cid>
         <xocs:timestamp>2015-10-14T13:03:12.206096-04:00</xocs:timestamp>
         <xocs:cover-date-start>2015-10-01</xocs:cover-date-start>
         <xocs:cover-date-end>2015-10-31</xocs:cover-date-end>
         <xocs:attachments>
            <xocs:web-pdf>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-main.pdf</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/MAIN/application/pdf/5be319767235430d65d5e55ef982cf02/main.pdf</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/MAIN/application/pdf/5be319767235430d65d5e55ef982cf02/main.pdf</xocs:ucs-locator>
               <xocs:filename>main.pdf</xocs:filename>
               <xocs:extension>pdf</xocs:extension>
               <xocs:pdf-optimized>true</xocs:pdf-optimized>
               <xocs:filesize>2046982</xocs:filesize>
               <xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose>
               <xocs:web-pdf-page-count>11</xocs:web-pdf-page-count>
               <xocs:web-pdf-images>
                  <xocs:web-pdf-image>
                     <xocs:attachment-eid>1-s2.0-S0042698915001650-main_1.png</xocs:attachment-eid>
                     <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/PREVIEW/image/png/777699d85a9b11105721fe68c30dad2f/main_1.png</xocs:ucs-locator>
                     <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/PREVIEW/image/png/777699d85a9b11105721fe68c30dad2f/main_1.png</xocs:ucs-locator>
                     <xocs:filename>main_1.png</xocs:filename>
                     <xocs:extension>png</xocs:extension>
                     <xocs:filesize>56340</xocs:filesize>
                     <xocs:pixel-height>849</xocs:pixel-height>
                     <xocs:pixel-width>656</xocs:pixel-width>
                     <xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type>
                     <xocs:pdf-page-num>1</xocs:pdf-page-num>
                  </xocs:web-pdf-image>
               </xocs:web-pdf-images>
            </xocs:web-pdf>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc5.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc5/THUMBNAIL/image/gif/0156520f1f60c15e38a901e76d8b0e8d/mmc5.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc5/THUMBNAIL/image/gif/0156520f1f60c15e38a901e76d8b0e8d/mmc5.sml</xocs:ucs-locator>
               <xocs:file-basename>mmc5</xocs:file-basename>
               <xocs:filename>mmc5.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>31215</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>166</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc4.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc4/THUMBNAIL/image/gif/a069e8ec571974820542784d9e8e30f9/mmc4.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc4/THUMBNAIL/image/gif/a069e8ec571974820542784d9e8e30f9/mmc4.sml</xocs:ucs-locator>
               <xocs:file-basename>mmc4</xocs:file-basename>
               <xocs:filename>mmc4.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>29072</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>167</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc3.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc3/THUMBNAIL/image/gif/72c750add9b0b695f1e673f7d7970206/mmc3.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc3/THUMBNAIL/image/gif/72c750add9b0b695f1e673f7d7970206/mmc3.sml</xocs:ucs-locator>
               <xocs:file-basename>mmc3</xocs:file-basename>
               <xocs:filename>mmc3.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>27241</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>167</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc2.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc2/THUMBNAIL/image/gif/87a4197e2490cdc13261f277b821f5df/mmc2.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc2/THUMBNAIL/image/gif/87a4197e2490cdc13261f277b821f5df/mmc2.sml</xocs:ucs-locator>
               <xocs:file-basename>mmc2</xocs:file-basename>
               <xocs:filename>mmc2.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>24964</xocs:filesize>
               <xocs:pixel-height>163</xocs:pixel-height>
               <xocs:pixel-width>166</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc1.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc1/THUMBNAIL/image/gif/bcf23b3032d2a01faeeea09521457d74/mmc1.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc1/THUMBNAIL/image/gif/bcf23b3032d2a01faeeea09521457d74/mmc1.sml</xocs:ucs-locator>
               <xocs:file-basename>mmc1</xocs:file-basename>
               <xocs:filename>mmc1.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>13717</xocs:filesize>
               <xocs:pixel-height>163</xocs:pixel-height>
               <xocs:pixel-width>173</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc5.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc5/DOWNSAMPLED/image/jpeg/687553f0402f8c5b1da41b46b3e643d0/mmc5.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc5/DOWNSAMPLED/image/jpeg/687553f0402f8c5b1da41b46b3e643d0/mmc5.jpg</xocs:ucs-locator>
               <xocs:file-basename>mmc5</xocs:file-basename>
               <xocs:filename>mmc5.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>22317</xocs:filesize>
               <xocs:pixel-height>173</xocs:pixel-height>
               <xocs:pixel-width>176</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc4.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc4/DOWNSAMPLED/image/jpeg/01b6171f7e09ca36d05e7e521928fcfe/mmc4.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc4/DOWNSAMPLED/image/jpeg/01b6171f7e09ca36d05e7e521928fcfe/mmc4.jpg</xocs:ucs-locator>
               <xocs:file-basename>mmc4</xocs:file-basename>
               <xocs:filename>mmc4.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>22735</xocs:filesize>
               <xocs:pixel-height>173</xocs:pixel-height>
               <xocs:pixel-width>176</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc3.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc3/DOWNSAMPLED/image/jpeg/7dcf0c12d9711ea94e7e069fd2fb3c23/mmc3.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc3/DOWNSAMPLED/image/jpeg/7dcf0c12d9711ea94e7e069fd2fb3c23/mmc3.jpg</xocs:ucs-locator>
               <xocs:file-basename>mmc3</xocs:file-basename>
               <xocs:filename>mmc3.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>23879</xocs:filesize>
               <xocs:pixel-height>173</xocs:pixel-height>
               <xocs:pixel-width>176</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc2.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc2/DOWNSAMPLED/image/jpeg/57d4c3e323bcd393e513846fe32d2bd7/mmc2.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc2/DOWNSAMPLED/image/jpeg/57d4c3e323bcd393e513846fe32d2bd7/mmc2.jpg</xocs:ucs-locator>
               <xocs:file-basename>mmc2</xocs:file-basename>
               <xocs:filename>mmc2.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>21438</xocs:filesize>
               <xocs:pixel-height>165</xocs:pixel-height>
               <xocs:pixel-width>168</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc1.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc1/DOWNSAMPLED/image/jpeg/59889f1f036597e7e1e69fb3268c7b8f/mmc1.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc1/DOWNSAMPLED/image/jpeg/59889f1f036597e7e1e69fb3268c7b8f/mmc1.jpg</xocs:ucs-locator>
               <xocs:file-basename>mmc1</xocs:file-basename>
               <xocs:filename>mmc1.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>13645</xocs:filesize>
               <xocs:pixel-height>160</xocs:pixel-height>
               <xocs:pixel-width>169</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-MMC-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc5.mp4</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc5/MAIN/video/mp4/28d4bacd6657696cd1b3fe5303cb947c/mmc5.mp4</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc5/MAIN/video/mp4/28d4bacd6657696cd1b3fe5303cb947c/mmc5.mp4</xocs:ucs-locator>
               <xocs:file-basename>mmc5</xocs:file-basename>
               <xocs:filename>mmc5.mp4</xocs:filename>
               <xocs:extension>mp4</xocs:extension>
               <xocs:filesize>2627824</xocs:filesize>
               <xocs:attachment-type>VIDEO</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc4.mp4</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc4/MAIN/video/mp4/6b34addabb9eed223db3caf97b5bea8c/mmc4.mp4</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc4/MAIN/video/mp4/6b34addabb9eed223db3caf97b5bea8c/mmc4.mp4</xocs:ucs-locator>
               <xocs:file-basename>mmc4</xocs:file-basename>
               <xocs:filename>mmc4.mp4</xocs:filename>
               <xocs:extension>mp4</xocs:extension>
               <xocs:filesize>2655085</xocs:filesize>
               <xocs:attachment-type>VIDEO</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc3.mp4</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc3/MAIN/video/mp4/b132c873bc183209c388b4235c7c52f1/mmc3.mp4</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc3/MAIN/video/mp4/b132c873bc183209c388b4235c7c52f1/mmc3.mp4</xocs:ucs-locator>
               <xocs:file-basename>mmc3</xocs:file-basename>
               <xocs:filename>mmc3.mp4</xocs:filename>
               <xocs:extension>mp4</xocs:extension>
               <xocs:filesize>2920107</xocs:filesize>
               <xocs:attachment-type>VIDEO</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc2.mp4</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc2/MAIN/video/mp4/fa7f04c0ab2ec7994c0060ce7d285567/mmc2.mp4</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc2/MAIN/video/mp4/fa7f04c0ab2ec7994c0060ce7d285567/mmc2.mp4</xocs:ucs-locator>
               <xocs:file-basename>mmc2</xocs:file-basename>
               <xocs:filename>mmc2.mp4</xocs:filename>
               <xocs:extension>mp4</xocs:extension>
               <xocs:filesize>6981284</xocs:filesize>
               <xocs:attachment-type>VIDEO</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc1.mp4</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc1/MAIN/video/mp4/cc41e5d922ee27d4c5868c88179a82e8/mmc1.mp4</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc1/MAIN/video/mp4/cc41e5d922ee27d4c5868c88179a82e8/mmc1.mp4</xocs:ucs-locator>
               <xocs:file-basename>mmc1</xocs:file-basename>
               <xocs:filename>mmc1.mp4</xocs:filename>
               <xocs:extension>mp4</xocs:extension>
               <xocs:filesize>9122812</xocs:filesize>
               <xocs:attachment-type>VIDEO</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr1_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr1/HIGHRES/image/jpeg/472f5e185c01847f8a7da9daaaa7b357/gr1_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr1/HIGHRES/image/jpeg/472f5e185c01847f8a7da9daaaa7b357/gr1_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>219114</xocs:filesize>
               <xocs:pixel-height>1964</xocs:pixel-height>
               <xocs:pixel-width>2933</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx2_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx2/HIGHRES/image/jpeg/d285ef05f687bd2e4e5ca7d82f87a0f7/fx2_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx2/HIGHRES/image/jpeg/d285ef05f687bd2e4e5ca7d82f87a0f7/fx2_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>fx2</xocs:file-basename>
               <xocs:filename>fx2_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>150356</xocs:filesize>
               <xocs:pixel-height>1190</xocs:pixel-height>
               <xocs:pixel-width>1644</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx1_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx1/HIGHRES/image/jpeg/e53ff082a42ed99ebf94c05285df2304/fx1_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx1/HIGHRES/image/jpeg/e53ff082a42ed99ebf94c05285df2304/fx1_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>fx1</xocs:file-basename>
               <xocs:filename>fx1_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>165452</xocs:filesize>
               <xocs:pixel-height>1453</xocs:pixel-height>
               <xocs:pixel-width>1578</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr9_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr9/HIGHRES/image/jpeg/a8d2aa060943aecfd857a267573de6ec/gr9_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr9/HIGHRES/image/jpeg/a8d2aa060943aecfd857a267573de6ec/gr9_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>118039</xocs:filesize>
               <xocs:pixel-height>1016</xocs:pixel-height>
               <xocs:pixel-width>1673</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr8_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr8/HIGHRES/image/jpeg/441b3a1014ca6cef7bd751ced2d314d3/gr8_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr8/HIGHRES/image/jpeg/441b3a1014ca6cef7bd751ced2d314d3/gr8_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>257811</xocs:filesize>
               <xocs:pixel-height>2344</xocs:pixel-height>
               <xocs:pixel-width>1672</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr7_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr7/HIGHRES/image/jpeg/ac2567976b4e901bf771bcffa48d6205/gr7_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr7/HIGHRES/image/jpeg/ac2567976b4e901bf771bcffa48d6205/gr7_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>164855</xocs:filesize>
               <xocs:pixel-height>1105</xocs:pixel-height>
               <xocs:pixel-width>1674</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr6_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr6/HIGHRES/image/jpeg/9de7c300685c8a969f148cbe66041be0/gr6_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr6/HIGHRES/image/jpeg/9de7c300685c8a969f148cbe66041be0/gr6_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>205304</xocs:filesize>
               <xocs:pixel-height>2048</xocs:pixel-height>
               <xocs:pixel-width>2760</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr5_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr5/HIGHRES/image/jpeg/f21aeeb3a659147963cc8d6394f652b4/gr5_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr5/HIGHRES/image/jpeg/f21aeeb3a659147963cc8d6394f652b4/gr5_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>202382</xocs:filesize>
               <xocs:pixel-height>1949</xocs:pixel-height>
               <xocs:pixel-width>1579</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr4_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr4/HIGHRES/image/jpeg/7976f94960a5682b7714c6ad20472f2b/gr4_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr4/HIGHRES/image/jpeg/7976f94960a5682b7714c6ad20472f2b/gr4_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>212034</xocs:filesize>
               <xocs:pixel-height>1476</xocs:pixel-height>
               <xocs:pixel-width>1673</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr3_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr3/HIGHRES/image/jpeg/c7e6fa2d1873d5c34b0b109901e444b3/gr3_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr3/HIGHRES/image/jpeg/c7e6fa2d1873d5c34b0b109901e444b3/gr3_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>80673</xocs:filesize>
               <xocs:pixel-height>964</xocs:pixel-height>
               <xocs:pixel-width>1378</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr2_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr2/HIGHRES/image/jpeg/87a6eb4d47912be9cde386418b66935d/gr2_lrg.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr2/HIGHRES/image/jpeg/87a6eb4d47912be9cde386418b66935d/gr2_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>206474</xocs:filesize>
               <xocs:pixel-height>1298</xocs:pixel-height>
               <xocs:pixel-width>2166</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc5.flv</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc5/OPT-STREAM/video/x-flv/131a56786ace62124fa72720b15819c3/mmc5.flv</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc5/OPT-STREAM/video/x-flv/131a56786ace62124fa72720b15819c3/mmc5.flv</xocs:ucs-locator>
               <xocs:file-basename>mmc5</xocs:file-basename>
               <xocs:filename>mmc5.flv</xocs:filename>
               <xocs:extension>flv</xocs:extension>
               <xocs:filesize>2967868</xocs:filesize>
               <xocs:attachment-type>VIDEO-FLASH</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc4.flv</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc4/OPT-STREAM/video/x-flv/124c6685243f3022c19a631233abaf29/mmc4.flv</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc4/OPT-STREAM/video/x-flv/124c6685243f3022c19a631233abaf29/mmc4.flv</xocs:ucs-locator>
               <xocs:file-basename>mmc4</xocs:file-basename>
               <xocs:filename>mmc4.flv</xocs:filename>
               <xocs:extension>flv</xocs:extension>
               <xocs:filesize>2965062</xocs:filesize>
               <xocs:attachment-type>VIDEO-FLASH</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc3.flv</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc3/OPT-STREAM/video/x-flv/f0be9f35b74a7a72bcd3e8ca7806bd45/mmc3.flv</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc3/OPT-STREAM/video/x-flv/f0be9f35b74a7a72bcd3e8ca7806bd45/mmc3.flv</xocs:ucs-locator>
               <xocs:file-basename>mmc3</xocs:file-basename>
               <xocs:filename>mmc3.flv</xocs:filename>
               <xocs:extension>flv</xocs:extension>
               <xocs:filesize>2950586</xocs:filesize>
               <xocs:attachment-type>VIDEO-FLASH</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc2.flv</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc2/OPT-STREAM/video/x-flv/5b8a332f9c8cc35aa36d600074542569/mmc2.flv</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc2/OPT-STREAM/video/x-flv/5b8a332f9c8cc35aa36d600074542569/mmc2.flv</xocs:ucs-locator>
               <xocs:file-basename>mmc2</xocs:file-basename>
               <xocs:filename>mmc2.flv</xocs:filename>
               <xocs:extension>flv</xocs:extension>
               <xocs:filesize>6521228</xocs:filesize>
               <xocs:attachment-type>VIDEO-FLASH</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc1.flv</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc1/OPT-STREAM/video/x-flv/a154a03df325116d81bc49a56f084356/mmc1.flv</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc1/OPT-STREAM/video/x-flv/a154a03df325116d81bc49a56f084356/mmc1.flv</xocs:ucs-locator>
               <xocs:file-basename>mmc1</xocs:file-basename>
               <xocs:filename>mmc1.flv</xocs:filename>
               <xocs:extension>flv</xocs:extension>
               <xocs:filesize>8562597</xocs:filesize>
               <xocs:attachment-type>VIDEO-FLASH</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr1.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr1/DOWNSAMPLED/image/jpeg/ca6d135c84783b2623b9cd85557292e1/gr1.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr1/DOWNSAMPLED/image/jpeg/ca6d135c84783b2623b9cd85557292e1/gr1.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>37325</xocs:filesize>
               <xocs:pixel-height>443</xocs:pixel-height>
               <xocs:pixel-width>662</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx2.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx2/DOWNSAMPLED/image/jpeg/d2c00d7dcb06fde846036066232ab332/fx2.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx2/DOWNSAMPLED/image/jpeg/d2c00d7dcb06fde846036066232ab332/fx2.jpg</xocs:ucs-locator>
               <xocs:file-basename>fx2</xocs:file-basename>
               <xocs:filename>fx2.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>21999</xocs:filesize>
               <xocs:pixel-height>269</xocs:pixel-height>
               <xocs:pixel-width>371</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx1.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx1/DOWNSAMPLED/image/jpeg/af9c6add0ba2927332208ee097652cea/fx1.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx1/DOWNSAMPLED/image/jpeg/af9c6add0ba2927332208ee097652cea/fx1.jpg</xocs:ucs-locator>
               <xocs:file-basename>fx1</xocs:file-basename>
               <xocs:filename>fx1.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>25421</xocs:filesize>
               <xocs:pixel-height>328</xocs:pixel-height>
               <xocs:pixel-width>356</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr9.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr9/DOWNSAMPLED/image/jpeg/7b19ea09c5856af0befe77db42b14d71/gr9.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr9/DOWNSAMPLED/image/jpeg/7b19ea09c5856af0befe77db42b14d71/gr9.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>16157</xocs:filesize>
               <xocs:pixel-height>230</xocs:pixel-height>
               <xocs:pixel-width>378</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr8.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr8/DOWNSAMPLED/image/jpeg/82de462562fecda23b5300aa27c4030d/gr8.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr8/DOWNSAMPLED/image/jpeg/82de462562fecda23b5300aa27c4030d/gr8.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>42479</xocs:filesize>
               <xocs:pixel-height>529</xocs:pixel-height>
               <xocs:pixel-width>377</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr7.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr7/DOWNSAMPLED/image/jpeg/e9940c4760beb214c10780a61ab0fb6c/gr7.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr7/DOWNSAMPLED/image/jpeg/e9940c4760beb214c10780a61ab0fb6c/gr7.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>25207</xocs:filesize>
               <xocs:pixel-height>250</xocs:pixel-height>
               <xocs:pixel-width>378</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr6.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr6/DOWNSAMPLED/image/jpeg/d17dcd7c4d70b09227cd2285280f1898/gr6.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr6/DOWNSAMPLED/image/jpeg/d17dcd7c4d70b09227cd2285280f1898/gr6.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>40740</xocs:filesize>
               <xocs:pixel-height>462</xocs:pixel-height>
               <xocs:pixel-width>623</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr5.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr5/DOWNSAMPLED/image/jpeg/fe0d333be0bbac9c7611259c482a512e/gr5.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr5/DOWNSAMPLED/image/jpeg/fe0d333be0bbac9c7611259c482a512e/gr5.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>25716</xocs:filesize>
               <xocs:pixel-height>439</xocs:pixel-height>
               <xocs:pixel-width>356</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr4.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr4/DOWNSAMPLED/image/jpeg/0d46ca35657172265ba3f4c7eceb6964/gr4.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr4/DOWNSAMPLED/image/jpeg/0d46ca35657172265ba3f4c7eceb6964/gr4.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>31057</xocs:filesize>
               <xocs:pixel-height>333</xocs:pixel-height>
               <xocs:pixel-width>378</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr3.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr3/DOWNSAMPLED/image/jpeg/5068d38a941ef9a86148ae9833ee2021/gr3.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr3/DOWNSAMPLED/image/jpeg/5068d38a941ef9a86148ae9833ee2021/gr3.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>11925</xocs:filesize>
               <xocs:pixel-height>218</xocs:pixel-height>
               <xocs:pixel-width>311</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr2.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr2/DOWNSAMPLED/image/jpeg/4e98db00516fedfae9f890f380fc5a7c/gr2.jpg</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr2/DOWNSAMPLED/image/jpeg/4e98db00516fedfae9f890f380fc5a7c/gr2.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>30261</xocs:filesize>
               <xocs:pixel-height>293</xocs:pixel-height>
               <xocs:pixel-width>489</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr1.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr1/THUMBNAIL/image/gif/2fca120f0b4151e6856b20c6a8433943/gr1.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr1/THUMBNAIL/image/gif/2fca120f0b4151e6856b20c6a8433943/gr1.sml</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>7595</xocs:filesize>
               <xocs:pixel-height>147</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx2.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx2/THUMBNAIL/image/gif/efdb623c8cf5d7e772efa1a12738a4b2/fx2.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx2/THUMBNAIL/image/gif/efdb623c8cf5d7e772efa1a12738a4b2/fx2.sml</xocs:ucs-locator>
               <xocs:file-basename>fx2</xocs:file-basename>
               <xocs:filename>fx2.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>7707</xocs:filesize>
               <xocs:pixel-height>159</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-fx1.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/fx1/THUMBNAIL/image/gif/b8d1f85a88af9bd8cf35ddc4a55fd36d/fx1.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/fx1/THUMBNAIL/image/gif/b8d1f85a88af9bd8cf35ddc4a55fd36d/fx1.sml</xocs:ucs-locator>
               <xocs:file-basename>fx1</xocs:file-basename>
               <xocs:filename>fx1.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>7116</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>178</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr9.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr9/THUMBNAIL/image/gif/ef16e7594cff73033275436fde839e4a/gr9.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr9/THUMBNAIL/image/gif/ef16e7594cff73033275436fde839e4a/gr9.sml</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>4245</xocs:filesize>
               <xocs:pixel-height>133</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr8.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr8/THUMBNAIL/image/gif/b881f3635b95120699f7d0f082fd1bee/gr8.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr8/THUMBNAIL/image/gif/b881f3635b95120699f7d0f082fd1bee/gr8.sml</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>8858</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>117</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr7.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr7/THUMBNAIL/image/gif/c5f8a805d9fd2291b43e9df908c3cb08/gr7.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr7/THUMBNAIL/image/gif/c5f8a805d9fd2291b43e9df908c3cb08/gr7.sml</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>8559</xocs:filesize>
               <xocs:pixel-height>145</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr6.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr6/THUMBNAIL/image/gif/5676e6476677d27c9d0acccb8343ab86/gr6.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr6/THUMBNAIL/image/gif/5676e6476677d27c9d0acccb8343ab86/gr6.sml</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>15979</xocs:filesize>
               <xocs:pixel-height>163</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr5.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr5/THUMBNAIL/image/gif/328013b958a9dd9d1d58d32554915dbb/gr5.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr5/THUMBNAIL/image/gif/328013b958a9dd9d1d58d32554915dbb/gr5.sml</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>4743</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>133</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr4.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr4/THUMBNAIL/image/gif/deab960a776dbacd1f6e7a52ee68ac1e/gr4.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr4/THUMBNAIL/image/gif/deab960a776dbacd1f6e7a52ee68ac1e/gr4.sml</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>8454</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>186</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr3.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr3/THUMBNAIL/image/gif/4647d36d3d5f12347fd311c99ae207ef/gr3.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr3/THUMBNAIL/image/gif/4647d36d3d5f12347fd311c99ae207ef/gr3.sml</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>5307</xocs:filesize>
               <xocs:pixel-height>153</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-gr2.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/gr2/THUMBNAIL/image/gif/268754dad3d14d471bafbe4183754223/gr2.sml</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/gr2/THUMBNAIL/image/gif/268754dad3d14d471bafbe4183754223/gr2.sml</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>6928</xocs:filesize>
               <xocs:pixel-height>131</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0042698915001650-mmc6.pdf</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0042698915001650/mmc6/MAIN/application/pdf/ee2fc2ff7ad50bcf464116e7e4cccd87/mmc6.pdf</xocs:ucs-locator>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0042698915001650/mmc6/MAIN/application/pdf/ee2fc2ff7ad50bcf464116e7e4cccd87/mmc6.pdf</xocs:ucs-locator>
               <xocs:file-basename>mmc6</xocs:file-basename>
               <xocs:filename>mmc6.pdf</xocs:filename>
               <xocs:extension>pdf</xocs:extension>
               <xocs:pdf-optimized>false</xocs:pdf-optimized>
               <xocs:filesize>812604</xocs:filesize>
               <xocs:attachment-type>APPLICATION</xocs:attachment-type>
            </xocs:attachment>
         </xocs:attachments>
      </xocs:attachment-metadata-doc>
   </xocs:meta>
   <xocs:serial-item>
      <article xmlns="http://www.elsevier.com/xml/ja/dtd" docsubtype="fla" xml:lang="en" version="5.2">
         <item-info>
            <jid>VR</jid>
            <aid>7084</aid>
            <ce:pii>S0042-6989(15)00165-0</ce:pii>
            <ce:doi>10.1016/j.visres.2015.05.001</ce:doi>
            <ce:copyright type="full-transfer" year="2015">Elsevier Ltd</ce:copyright>
         </item-info>
         <ce:floats>
            <ce:figure id="f0005">
               <ce:label>Fig. 1</ce:label>
               <ce:caption id="cn0080">
                  <ce:simple-para id="sp0020" view="all">(A) An example stimulus with 25 spheres. Participants were asked to judge as soon as possible whether a target existed in the stimulus. (B) The direction (tilt) of the light source varied between −135 and +180°. (C) Examples of stimuli with no highlight (left), weak highlight (middle), and strong highlight (right).</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr1"/>
            </ce:figure>
            <ce:figure id="f0010">
               <ce:label>Fig. 2</ce:label>
               <ce:caption id="cn0085">
                  <ce:simple-para id="sp0025" view="all">The mean reaction time as a function of lighting direction (tilt) for the three highlight conditions. Solid (red), short-dashed (green), and long-dashed (blue) lines indicate no, weak, and strong highlight conditions, respectively. The reaction times for stimuli with highlights were shorter than those without highlights (shading only). The error bars indicate the standard error among participants. The abscissa is the light-source direction of the <ce:italic>distractors</ce:italic>. We chose this because the reaction time for top-light distractors (bottom-light for a target) is faster than the others (<ce:cross-ref refid="b0045" id="c0005">Kawabe &amp; Miura, 2004</ce:cross-ref>; <ce:cross-ref refid="b0025" id="c0010">Chacón, 2004</ce:cross-ref>).</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr2"/>
            </ce:figure>
            <ce:figure id="f0015">
               <ce:label>Fig. 3</ce:label>
               <ce:caption id="cn0090">
                  <ce:simple-para id="sp0030" view="all">The magnitude of facilitation (i.e., the difference in reaction times between the no-highlight and strong-highlight conditions) as a function of the lighting direction (tilt). The error bars indicate the standard error among participants. The lighting direction was not a significant factor of the magnitude.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr3"/>
            </ce:figure>
            <ce:figure id="f0020">
               <ce:label>Fig. 4</ce:label>
               <ce:caption id="cn0095">
                  <ce:simple-para id="sp0035" view="all">The mean reaction time for inconsistent, orthogonal, orthogonal-opposite and highlight-only conditions as a function of lighting direction. The inconsistent highlights showed facilitation, while the orthogonal highlights did not alter the reaction time, indicating that an addition of highlights may evoke facilitation but not suppression. The conventions are identical to those in <ce:cross-ref refid="f0010" id="c0015">Fig. 2</ce:cross-ref>.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr4"/>
            </ce:figure>
            <ce:figure id="f0025">
               <ce:label>Fig. 5</ce:label>
               <ce:caption id="cn0100">
                  <ce:simple-para id="sp0040" view="all">The luminance histograms for shading, strong, and inconsistent highlights. The strong highlights showed high skewness (5.22), while shading and inconsistent highlights showed lower skews (3.62 and 3.15, respectively). The luminance skew cannot account for the facilitation in searching time.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr5"/>
            </ce:figure>
            <ce:figure id="f0030">
               <ce:label>Fig. 6</ce:label>
               <ce:caption id="cn0105">
                  <ce:simple-para id="sp0045" view="all">(A) Examples of the image-based highlights (without shading). Small red dots show the center of gravity of the highlights. (B) Examples of rendered spheres with the image-based highlights and computer-generated shading. (C) An example of a 5<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>5 array.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr6"/>
            </ce:figure>
            <ce:figure id="f0035">
               <ce:label>Fig. 7</ce:label>
               <ce:caption id="cn0110">
                  <ce:simple-para id="sp0050" view="all">The mean reaction time for stimuli with the image-based highlights as a function of lighting direction. The image-based highlights showed facilitation, while inconsistent highlights did not alter the reaction time.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr7"/>
            </ce:figure>
            <ce:figure id="f0040">
               <ce:label>Fig. 8</ce:label>
               <ce:caption id="cn0115">
                  <ce:simple-para id="sp0055" view="all">Examples of stimuli for the depth discrimination experiment. The top panel illustrates the spatial organization of the surface in examination including the directions of viewer and light source. The bottom panels show six examples of stimuli with the identical terrain. The lighting direction for highlights is indicated beneath each panel. The lighting direction for shading was fixed as top-left for all stimuli. We tested 50 terrains with six conditions: five lighting directions for highlights and a no-highlight condition.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr8"/>
            </ce:figure>
            <ce:figure id="f0045">
               <ce:label>Fig. 9</ce:label>
               <ce:caption id="cn0120">
                  <ce:simple-para id="sp0060" view="all">The mean correct response rates for the six conditions. The error bars indicate the standard error. Highlights facilitated the discrimination even when their lighting directions deviated from those of the shading.</ce:simple-para>
               </ce:caption>
               <ce:link locator="gr9"/>
            </ce:figure>
            <ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" frame="topbot" id="t0005" rowsep="0" colsep="0">
               <ce:label>Table 1</ce:label>
               <ce:caption id="cn0125">
                  <ce:simple-para id="sp0065" view="all">The luminance contrast of highlights for all highlight conditions used in Experiment 2. The second and third columns show the Michelson contrast of highlights with respect to background and immediate surround, respectively (see the main text for details). The reaction time was independent of contrast.</ce:simple-para>
               </ce:caption>
               <tgroup cols="1">
                  <colspec colname="col1" align="left"/>
                  <tbody>
                     <row rowsep="1" valign="top">
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd">
                           <inline-figure baseline="0.0">
                              <link locator="fx1"/>
                           </inline-figure>
                        </entry>
                     </row>
                  </tbody>
               </tgroup>
            </ce:table>
            <ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" frame="topbot" id="t0010" rowsep="0" colsep="0">
               <ce:label>Table 2</ce:label>
               <ce:caption id="cn0130">
                  <ce:simple-para id="sp0070" view="all">The luminance contrast of highlights for all highlight conditions used in Experiment 3. The conventions are the same as those in <ce:cross-ref refid="t0005" id="c0020">Table 1</ce:cross-ref>. The reaction time was independent of contrast.</ce:simple-para>
               </ce:caption>
               <tgroup cols="1">
                  <colspec colname="col1" align="left"/>
                  <tbody>
                     <row valign="top">
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd">
                           <inline-figure baseline="0.0">
                              <link locator="fx2"/>
                           </inline-figure>
                        </entry>
                     </row>
                  </tbody>
               </tgroup>
            </ce:table>
         </ce:floats>
         <head>
            <ce:title id="tm005">Facilitatory mechanisms of specular highlights in the perception of depth</ce:title>
            <ce:author-group id="ag005">
               <ce:author orcid="0000-0002-6960-1520" id="au005">
                  <ce:given-name>Ko</ce:given-name>
                  <ce:surname>Sakai</ce:surname>
                  <ce:cross-ref refid="cor1" id="c0025">
                     <ce:sup loc="post">⁎</ce:sup>
                  </ce:cross-ref>
                  <ce:e-address type="email" id="em005">sakai@cs.tsukuba.ac.jp</ce:e-address>
                  <ce:e-address type="url" id="em010">http://www.cvs.cs.tsukuba.ac.jp</ce:e-address>
               </ce:author>
               <ce:author id="au010">
                  <ce:given-name>Ryoko</ce:given-name>
                  <ce:surname>Meiji</ce:surname>
               </ce:author>
               <ce:author id="au015">
                  <ce:given-name>Tetsuya</ce:given-name>
                  <ce:surname>Abe</ce:surname>
               </ce:author>
               <ce:affiliation id="af005">
                  <ce:textfn>Department of Computer Science, University of Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, Japan</ce:textfn>
                  <sa:affiliation>
                     <sa:organization>Department of Computer Science</sa:organization>
                     <sa:organization>University of Tsukuba</sa:organization>
                     <sa:address-line>1-1-1 Tennodai</sa:address-line>
                     <sa:city>Tsukuba</sa:city>
                     <sa:state>Ibaraki</sa:state>
                     <sa:postal-code>305-8573</sa:postal-code>
                     <sa:country>Japan</sa:country>
                  </sa:affiliation>
               </ce:affiliation>
               <ce:correspondence id="cor1">
                  <ce:label>⁎</ce:label>
                  <ce:text>Corresponding author.</ce:text>
               </ce:correspondence>
            </ce:author-group>
            <ce:date-received day="8" month="4" year="2014"/>
            <ce:date-revised day="4" month="5" year="2015"/>
            <ce:abstract class="author-highlights" xml:lang="en" id="ab005" view="all">
               <ce:section-title id="st005">Highlights</ce:section-title>
               <ce:abstract-sec id="as005" view="all">
                  <ce:simple-para id="sp0005" view="all">
                     <ce:list id="l0005">
                        <ce:list-item id="o0005">
                           <ce:label>•</ce:label>
                           <ce:para id="p0005" view="all">Specular highlights facilitate visual search for shaded objects.</ce:para>
                        </ce:list-item>
                        <ce:list-item id="o0010">
                           <ce:label>•</ce:label>
                           <ce:para id="p0010" view="all">Inconsistent lighting between shading and highlights does not suppress search.</ce:para>
                        </ce:list-item>
                        <ce:list-item id="o0015">
                           <ce:label>•</ce:label>
                           <ce:para id="p0015" view="all">Highlights facilitate depth discrimination regardless of inconsistency in lighting.</ce:para>
                        </ce:list-item>
                     </ce:list>
                  </ce:simple-para>
               </ce:abstract-sec>
            </ce:abstract>
            <ce:abstract class="author" xml:lang="en" id="ab010" view="all">
               <ce:section-title id="st010">Abstract</ce:section-title>
               <ce:abstract-sec id="as010" view="all">
                  <ce:simple-para id="sp0010" view="all">We investigated whether specular highlights facilitate the perception of shape from shading in a search paradigm and how highlights interact with shading to facilitate this perception. Our results indicated that stimuli containing highlights led to shorter searching time with the dependence on the light source direction (top lights make searching faster), suggesting that highlights indeed facilitate shape-from-shading processing. To examine how highlight processing interacts with shading processing, we tested unnatural stimuli for which the lighting directions for shading and highlights were inconsistent. The results indicated that unnatural highlights (bright spots) placed in a direction inconsistent with the shading either decrease or do not alter searching time. This suggests that highlights may facilitate, and not suppress, shading processing. With more physically plausible highlights generated from image-based lighting, we also observed facilitation with consistent highlights, but no change with inconsistent highlights. Finally, we examined whether highlights indeed work to facilitate depth perception in a discrimination task. The results showed that correct discrimination of depth increases when highlights are added to shading even when their lighting directions are inconsistent. These results indicate that specular highlights facilitate shading processing, and do not suppress it even when the highlights are placed in a direction inconsistent with shading. The results also elucidate the lighting constraints of the visual system.</ce:simple-para>
               </ce:abstract-sec>
            </ce:abstract>
            <ce:keywords class="keyword" id="kg005" view="all">
               <ce:section-title id="st015">Keywords</ce:section-title>
               <ce:keyword id="k0005">
                  <ce:text>Shading</ce:text>
               </ce:keyword>
               <ce:keyword id="k0010">
                  <ce:text>Pop-out</ce:text>
               </ce:keyword>
               <ce:keyword id="k0015">
                  <ce:text>Specular highlights</ce:text>
               </ce:keyword>
               <ce:keyword id="k0020">
                  <ce:text>Search paradigm</ce:text>
               </ce:keyword>
               <ce:keyword id="k0025">
                  <ce:text>Depth discrimination</ce:text>
               </ce:keyword>
            </ce:keywords>
         </head>
         <body view="all">
            <ce:sections>
               <ce:section role="introduction" id="s0005" view="all">
                  <ce:label>1</ce:label>
                  <ce:section-title id="st020">Introduction</ce:section-title>
                  <ce:para id="p0020" view="all">Specular highlights have substantial effects on the perception of shape, depth, and surface appearance. For example, a smear of white on a shaded image, called “pointillé” in oil painting, greatly enhances the perceived reality of a shape in addition to improving its surface appearance. Psychophysical studies have reported that simple specular highlights facilitate the perception of curvature and shape (<ce:cross-refs refid="b0090 b0075" id="r0005">Norman, Todd, &amp; Orban, 2004; Nefs, 2008</ce:cross-refs>). Recently, <ce:cross-ref refid="b0120" id="c0030">Wijntjes et al. (2012)</ce:cross-ref> showed that the elimination of specular highlights from shading (matte and velvet surfaces) degrades the perception of shape. Controversially, other studies have reported that specular highlights do not facilitate the perception of the detailed structure of a three-dimensional (3D) shape. Instead, they claim that the perception of a detailed shape (surface normals) as measured by a “needle probe” depends on a bidirectional reflectance distribution function (BRDF) and lighting, but not on specular highlights and surface glossiness (<ce:cross-refs refid="b0080 b0050" id="r0010">Nefs, Koenderink, &amp; Kappers, 2006; Khang, Koenderink, &amp; Kappers, 2007</ce:cross-refs>). However, these experiments used stimuli that included other cues, such as complex contours and textures, which may complicate cue integration and veil the interaction between highlights and shading. The present study focused on whether specular highlights facilitate shading processing, and if so, how highlights interact with shading to facilitate perception.</ce:para>
                  <ce:para id="p0025" view="all">An image projected onto the retina is determined by lighting, surface reflectance, and object shape. Although the appearance of shading and highlights significantly differ, shading and highlights, the diffuse and specular components of a reflection, simultaneously exist in nature except for the extreme cases of matte and mirror. They share the same constraints of lighting and shape. Understanding how the visual system processes shading and highlights in shape perception and how it utilizes their coexistence under the same constraint would shed light on the mechanisms of integration, and further on the neural mechanisms that solve the ill-posed problem of the simultaneous estimation of lighting, reflectance, and shape.</ce:para>
                  <ce:para id="p0030" view="all">Psychophysical studies using a search paradigm have shown a crucial constraint of lighting in shape from shading (e.g., <ce:cross-refs refid="b0100 b0010 b0055" id="r0015">Ramachandran, 1988; Aks &amp; Enns, 1992; Kleffner &amp; Ramachandran, 1992</ce:cross-refs>). It was observed that targets pop out from distractors with a light-source direction that is the opposite of the target’s. The time used for searching for targets is a function of light-source direction; that is, detection is fast with top-left lighting and slow with lateral lighting (<ce:cross-ref refid="b0110" id="c0035">Sun &amp; Perona, 1998</ce:cross-ref>). This dependence is considered evidence for the light-from-above constraint in shape from shading. <ce:cross-ref refid="b0030" id="c0040">Champion and Adams (2007)</ce:cross-ref> reported that the preference for overhead lighting was not modifiable by training, which is consistent with the involvement of the constraint in pre-attentive processing.</ce:para>
                  <ce:para id="p0035" view="all">We investigated whether specular highlights facilitate shading processing in searching time, and if so, how highlights interact with shading to do so. We utilized the light-direction dependence of searching time as an indication of shading processing. The changes in searching time and light-direction dependence, for a combination of shading and highlights, would provide evidence for the integration process of the two cues. If we observe light-direction dependence when highlights are added to shading, this suggests that highlights work, as they facilitate shading processing. Alternatively, if the dependence disappears or weakens when highlights are added, this suggests that highlights are processed independently from shading. Our results showed light-direction dependence and less searching time, suggesting that highlights work, as they facilitate shading processing (Experiment 1).</ce:para>
                  <ce:para id="p0040" view="all">To examine further how highlight processing works with shading processing, we tested unnatural stimuli for which lighting directions for shading and highlights were inconsistent (Experiment 2). With inconsistent lighting, the perceptual degree of glossiness appeared to decrease, and the highlights could appear as bright spots (a change in albedo). The results showed light-direction dependence without an increase in searching time, suggesting that inconsistent highlights do not suppress shading processing. The results further indicated that low-level differences in the stimuli, such as the location and contrast of bright spots, do not account for searching time. Additional experiments (Experiment 3) showed the same results for image-based highlights in which the shape of the light source is visible on an object. Finally, to ascertain whether the highlight has a facilitative function in the perception of depth, we conducted experiments with a depth-discrimination task using random surfaces (Experiment 4). The results showed that the correct response rate increases when highlights are added to shading, even if their lighting directions are inconsistent so that they do not fully contribute to the perception of glossiness. These results indicate that specular highlights have a facilitative function in the perception of depth, not a suppressive function, even when the light sources are inconsistent between highlights and shading.</ce:para>
               </ce:section>
               <ce:section id="s0010" view="all">
                  <ce:label>2</ce:label>
                  <ce:section-title id="st025">Experiment 1</ce:section-title>
                  <ce:para id="p0045" view="all">To examine whether specular highlights facilitate shading processing, we utilized a search paradigm (e.g., <ce:cross-refs refid="b0100 b0010 b0055" id="r0020">Ramachandran, 1988; Aks &amp; Enns, 1992; Kleffner &amp; Ramachandran, 1992</ce:cross-refs>). The searching time and its light-direction dependence are expected to illustrate the characteristics of highlights. If we observe the light-direction dependence with less searching time when highlights are added to shading, it suggests that highlights work, as they facilitate shading processing.</ce:para>
                  <ce:section id="s0015" view="all">
                     <ce:label>2.1</ce:label>
                     <ce:section-title id="st030">Method</ce:section-title>
                     <ce:section id="s0020" view="all">
                        <ce:label>2.1.1</ce:label>
                        <ce:section-title id="st035">Stimuli</ce:section-title>
                        <ce:para id="p0050" view="all">The stimuli were an array of 25 spheres generated by computer graphics (Open GL 2.1), as shown in <ce:cross-ref refid="f0005" id="c0045">Fig. 1</ce:cross-ref>
                           <ce:float-anchor refid="f0005"/>(A). The visual angle of each sphere was 1.0°. The spheres were placed on a 5<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>5 grid with or without small random displacements of up to 0.37° in visual angle. Shading of spheres was rendered with a Phong model as they were illuminated by a single light source and ambient light. The strength of diffuse and ambient reflectance was set constant for all stimuli (GL_DIFFUSE<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.5 and GL_AMBIENT<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.25 for glMaterialfv). The magnitudes of lights (for glLightfv) were set to 1.0 for all stimuli). All spheres except one were identical in their direction of light source (distractors). The tilt of their light source was randomly chosen to be between −135° and +180° with an increment of 45<ce:sup loc="post">o</ce:sup>, with respect to the top vertical in an anticlockwise direction (e.g., +90°, 0°, −90° for the left, top, and right, respectively), as shown in <ce:cross-ref refid="f0005" id="c0050">Fig. 1</ce:cross-ref>(B). In the following sections, we often refer to tilt as the direction in lighting. The slant of the light source was fixed to 51° with respect to the direction of the camera (viewer). The light source was placed at a significant distance from the spheres, and the distance between the spheres and the light source was fixed. The rest of one sphere (a target) was illuminated from the opposite direction in tilt while the slant was identical to that of the distractors. The position of a target on the 5<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>5 grid was randomly chosen. The intensity of shading ranged between 10.3 and 40.8<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>, and that of the background was 0.1<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>. Specular highlights were given by controlling the specularity of the material in OpenGL (GL_SPECULAR and GL_SHININESS). We used three highlight conditions: strong, weak, and no highlights (GL_SPECULAR<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>1.0, 0.5, and 0, respectively; GL_SHININESS<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>128.0 for all cases). The maximum intensities of the strong and weak highlights were 55.6 and 54.9<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>, respectively. The range of intensity for the weak highlights fell into the range of the display, but part of that for strong highlights was saturated. <ce:cross-ref refid="f0005" id="c0055">Fig. 1</ce:cross-ref>(C) shows examples of the highlights. The stimuli were presented on a CRT display (EIZO, T799) that was placed 0.9<ce:hsp sp="0.25"/>m in front of the participants. Masks presented between the stimuli consisted of small squares with an intensity randomly chosen from 0.1 to 25.5<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>.</ce:para>
                     </ce:section>
                     <ce:section id="s0025" view="all">
                        <ce:label>2.1.2</ce:label>
                        <ce:section-title id="st040">Procedures and participants</ce:section-title>
                        <ce:para id="p0055" view="all">The experiments were conducted in a dark room without any light except the display. A mask was presented for 2000<ce:hsp sp="0.25"/>ms. A fixation aid, a small red square at the center of the display, was superimposed on the mask for the first 1500<ce:hsp sp="0.25"/>ms and removed for the remaining 500<ce:hsp sp="0.25"/>ms. A stimulus of 5<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>5 spheres was presented following the mask. A target (with the light from the opposite direction in tilt) was presented within a stimulus for 90% of the times but not presented (all distractors) for 10%. Participants were asked to judge as soon as possible whether a target existed in the stimuli and to indicate their choice by clicking a mouse button. The elapsed time from the stimulus onset to the mouse click was measured as reaction time. The next mask was presented, when the button was pushed or 3000<ce:hsp sp="0.25"/>ms had passed after the stimulus onset.</ce:para>
                        <ce:para id="p0060" view="all">A total of 720 stimuli were presented to each participant. We recorded the responses from 660 stimuli (8 lighting directions and 25 target positions (600 stimuli with a target), and 60 no-target stimuli) and we discarded the first 60 responses that were shown at the beginning of the experiment, and when the highlight conditions changed. The participants repeated 60 trials for each of the highlight conditions (strong, weak, and no highlight), for a total of 180 trials in a row (one set). They completed four sets with a break in between. The order of the highlight conditions, location of targets, and direction of the light source were randomized. All participants showed almost perfect judgment responses on the appearance of targets.</ce:para>
                        <ce:para id="p0065" view="all">Six males and four females volunteered to participate in the experiment. All participants were aged in their 20<ce:hsp sp="0.25"/>s and had normal or corrected-to-normal vision. They were familiar with psychophysical experiments, but did not know the aim of the experiment. The experiments in the present studies were approved by the ethics committee of the institute and performed in accordance with The Code of Ethics of the World Medical Association (Declaration of Helsinki). Informed consent was obtained from the participants.</ce:para>
                     </ce:section>
                  </ce:section>
                  <ce:section role="results" id="s0030" view="all">
                     <ce:label>2.2</ce:label>
                     <ce:section-title id="st045">Results</ce:section-title>
                     <ce:para id="p0070" view="all">We measured the reaction time when searching for a target among distractors, to examine whether the addition of a specular highlight to shading decreases searching time. <ce:cross-ref refid="f0010" id="c0060">Fig. 2</ce:cross-ref>
                        <ce:float-anchor refid="f0010"/> shows the mean searching time for all subjects as a function of the lighting direction (tilt). The results for individuals are shown in <ce:cross-ref refid="s0125" id="c0065">Supplement 1</ce:cross-ref>. The reaction time for the shading condition shows a “V” shape; that is, searching is fastest with top-left lighting, and slowest with lateral lighting. This reproduces the preference for top-left lighting reported by <ce:cross-ref refid="b0110" id="c0070">Sun and Perona (1998)</ce:cross-ref>. The reaction times for the strong-highlight condition appear to be the shortest, followed by those for the weak-highlight condition. A three-way ANOVA showed significance for differences in highlight conditions (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01), lighting directions (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01), and participants (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01), but not for the interaction between highlights and lighting directions (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.80), indicating the facilitation by the highlights and dependence on lighting direction.</ce:para>
                     <ce:para id="p0075" view="all">To examine the magnitude of facilitation, we plotted the magnitude (i.e., the difference in reaction times between shading and strong-highlight conditions) for each lighting direction in <ce:cross-ref refid="f0015" id="c0075">Fig. 3</ce:cross-ref>
                        <ce:float-anchor refid="f0015"/>. The lighting direction was not a significant factor of the magnitude (one-way ANOVA, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.79). The mean differences in reaction times between shading and highlight conditions were 95<ce:hsp sp="0.25"/>ms and 70<ce:hsp sp="0.25"/>ms for strong and weak highlights, respectively, and these were significant (pairwise <ce:italic>t</ce:italic>-test, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01 for both highlight conditions). The magnitude of facilitation between strong and weak highlights was also significant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.016). These results indicate that the magnitude of facilitation is constant over lighting directions and that the dependence of searching time on lighting direction is maintained when facilitated by highlights. These results suggest that highlighting works to facilitate shading processing in terms of reaction time.</ce:para>
                  </ce:section>
                  <ce:section role="discussion" id="s0035" view="all">
                     <ce:label>2.3</ce:label>
                     <ce:section-title id="st050">Discussion</ce:section-title>
                     <ce:para id="p0080" view="all">The dependence of facilitation on specularity (strong or weak highlights) appears to be convincing evidence for the facilitation by specular highlights. The intensity range of the strong highlights condition exceeded the dynamic range of the monitor, so that the maximum luminance of the strong and weak highlights was similar (55.6 and 54.9<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>, respectively). However, the appearance of the stimuli in the strong and weak highlight conditions was clearly distinguishable because of the spatial extent of the bright region.</ce:para>
                     <ce:para id="p0085" view="all">The sole highlight component of stimuli, excluding the shading component, could be a cue for searching; however, as the next experiment showed, the highlight-only condition did not evoke pop-out, with the searching time being twice that of the shading condition. Therefore, the shortened reaction time in the highlight conditions cannot be accounted for by the spatial polarity of the highlights (e.g., either the top or bottom of a sphere). We also performed the experiment with contrast-reversed highlights, in which highlight components were darkened rather than brightened. The stimuli with the dark highlights did not evoke significant facilitation (pairwise <ce:italic>t</ce:italic>-test, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.06; see <ce:cross-ref refid="s0125" id="c0080">Supplement 2</ce:cross-ref>). These results support the view that the combination of shading and highlighting accounts for the facilitation. We discuss this issue further in the next section.</ce:para>
                     <ce:para id="p0090" view="all">With the classical stimuli with a linear gradient of luminance (e.g., <ce:cross-ref refid="b0100" id="c0085">Ramachandran, 1988</ce:cross-ref>), targets and distractors appear to be either convex or concave, depending on the direction of the gradient that corresponds to the direction of lighting. The perception from more physically plausible stimuli sometimes deviates from such a simple convex/concave appearance. Although a target in the stimuli shown in <ce:cross-ref refid="f0005" id="c0090">Fig. 1</ce:cross-ref> (Phong shading) may appear concave, that in <ce:cross-ref refid="f0030" id="c0095">Fig. 6</ce:cross-ref> (image-based highlight with a Ward model) for some participants may not. This is natural because we changed the lighting direction of the target but not the shape, so that the appearance of the target is different from that of a concave surface (the inside of a sphere). This difference tends to increase as the physical plausibility of a stimulus increases. Our stimuli, with Phong shading (<ce:cross-ref refid="f0005" id="c0100">Fig. 1</ce:cross-ref>) and a Ward model with image-based highlight (<ce:cross-ref refid="f0035" id="c0105">Fig. 7</ce:cross-ref>), were more physically plausible than the classical stimuli with a linear gradient. In this sense, our experiments may be distinct from the classical experiments that discussed shape from shading. Because we asked participants to detect a target, it is uncertain exactly what cue evoked detection in the visual system: the cue could be depth, shape, lighting direction or some other image features. We would like to note, however, that all participants reported their introspection that the apparent depth of a target was distinct from that of distractors, and that the reaction time showed the dependence on lighting direction (search asymmetry), which is persuasive evidence of shading processing. Therefore, we consider that detection was based on the shading processing that contributes to the perception of depth and shape. A further investigation is expected of which changes in perception (depth, shape or surface property) are relevant to the difference in reaction time.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0040" view="all">
                  <ce:label>3</ce:label>
                  <ce:section-title id="st055">Experiment 2</ce:section-title>
                  <ce:para id="p0095" view="all">Experiment 2 investigated how highlights facilitate shading processing in reaction time. Specifically, we examined how they interact with each other in unnatural environments where shading and highlights conflict with each other. We tested artificial stimuli for which the lighting directions for shading and highlights were inconsistent. To generate the stimuli, we independently controlled light sources for shading and highlighting. For instance, we placed a virtual light source for shading at the top and one for highlights at the bottom, generating highlights inconsistent with the shading (inconsistent condition). We also tested stimuli with highlights, but without shading, as a reference. When we turned off the light source for shading, highlights were generated without shading (highlight-only condition). Note that the unnatural placement of highlights, and the removal of shading, appeared to decrease the degree of perceptual glossiness. In such a case, a “highlight” may be better described as a “bright spot”. However, for the sake of consistency and simplicity we do not distinguish between these two terms. Furthermore, to counter the possibility that the existence of highlights could facilitate perception, we tested artificial highlights with their locations orthogonal to the shading gradient and identical between a target and distractors (orthogonal condition). We also tested the orthogonal highlights with their locations opposite between a target and distractors (orthogonal-opposite condition) in order to counter the possibility that the difference in location of highlights between a target and distractors could facilitate perception. The searching time for these conditions would provide evidence for the integration process of highlights and shading.</ce:para>
                  <ce:section id="s0045" view="all">
                     <ce:label>3.1</ce:label>
                     <ce:section-title id="st060">Method</ce:section-title>
                     <ce:para id="p0100" view="all">The stimuli were identical to those in Experiment 1 except for the lighting in OpenGL. The direction of the light source for the inconsistent highlight was set opposite to that for shading in tilt, while it was identical in slant. In this case, the lighting direction for the stimulus was defined as that of shading (the opposite of the highlight). For the highlight-only condition, the degree of diffuse reflectance (GL_DIFFUSE) was set at zero so that no shading appeared on the sphere. The degree of ambient reflectance was increased to GL_AMBIENT<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.5 so that the mean luminance was equal to that of the other types of stimuli. In this case, the direction of lighting for the stimulus was defined as that of the highlights. For the stimuli with spatially fixed highlights (orthogonal condition), the direction of the light source for highlights was randomly chosen from those orthogonal to the shading gradient. For each stimulus, this direction was kept identical among all spheres so that the highlight appeared in the same location throughout the spheres. The stimuli for the orthogonal-opposite condition were generated in a similar way, except for the direction of highlights for a target. The light source for the highlights of a target was placed in the opposite direction to that of the rest of the spheres (distractors). The material specularity for all highlight conditions was identical to that for the strong highlight condition in Experiment 1. Note that the unnatural placement of highlights, and the removal of shading, may decrease the degree of perceptual glossiness. In such a case, a “highlight” may be better described as a “bright spot”. However, we do not distinguish these two terms in this paper for the sake of consistency and simplicity. Procedures were also identical to those of Experiment 1 except for the total number of stimuli presented, because the number of conditions was increased. Six participants completed the experiment. Two of them had not participated in the previous experiment, but they shared the same conditions as Experiment 1.</ce:para>
                  </ce:section>
                  <ce:section id="s0050" view="all">
                     <ce:label>3.2</ce:label>
                     <ce:section-title id="st065">Results</ce:section-title>
                     <ce:para id="p0105" view="all">We measured the participants’ reaction times for searching for a target among distractors, as in Experiment 1. <ce:cross-ref refid="f0020" id="c0110">Fig. 4</ce:cross-ref>
                        <ce:float-anchor refid="f0020"/> shows the mean searching time for all participants as a function of the lighting direction (tilt). The reaction time for the highlight-only condition was in the range of 1.3 to 1.7<ce:hsp sp="0.25"/>s, about twice as long as that for the shading condition. This reaction time does not show dependence on the lighting direction (one-way ANOVA, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.16). Together with participants’ introspection, it appears that the highlight-only condition did not evoke a pre-attentive pop-out. The result indicates that, by itself, the highlight (a bright spot without shading) yields a perception distinct from that from shading. The difference in the location of highlights between a target and distractors appears to work as a low-level feature of the image, but it does not evoke a pre-attentive pop-out. This result indicates nonlinearity in the cue integration of shading and highlights, similar to the findings of <ce:cross-ref refid="b0020" id="c0115">Bülthoff (1991)</ce:cross-ref>.</ce:para>
                     <ce:para id="p0110" view="all">The mean searching time for the inconsistent condition shows a dependence on the lighting direction with the shortest reaction time for the top-left light, similar to the cases of the shading and highlight conditions in Experiment 1. The reaction times for the inconsistent condition appear shorter than those for the shading condition and similar to those for the consistent (strong) highlight condition. The reaction times for the orthogonal and orthogonal-opposite highlight conditions appear similar to those for the shading condition. A three-way ANOVA showed significant differences among the highlight conditions (shading, consistent, inconsistent, orthogonal and orthogonal-opposite highlights; <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01), lighting directions (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01), and participants (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01). These results suggest shorter reaction times for consistent and inconsistent highlights and their dependence on the lighting direction, as described in greater detail below.</ce:para>
                     <ce:para id="p0115" view="all">The mean differences in reaction times for consistent and inconsistent highlight conditions with respect to shading were 46<ce:hsp sp="0.25"/>ms and 44<ce:hsp sp="0.25"/>ms, respectively, and they were significant (pairwise <ce:italic>t</ce:italic>-test, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01 for both highlights). The difference between the consistent and inconsistent highlights was not significant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.85). These results show that the inconsistent highlights facilitate shading processing to an extent similar to the consistent highlights. The mean difference between the shading and orthogonal highlight conditions was 6<ce:hsp sp="0.25"/>ms, which was not significant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.63). This result shows that the existence of a bright region (highlight) does not account for the facilitation. The mean difference between the shading and orthogonal-opposite conditions was 9<ce:hsp sp="0.25"/>ms, which was not significant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.45). The orthogonal-opposite highlights did not alter perception in comparison with shading. The highlights in the directions parallel to the shading gradient evoked facilitation (consistent and inconsistent conditions), but those orthogonal to the shading did not (orthogonal-opposite conditions). We consider this dependence on the direction of highlights with respect to shading to be evidence of highlight processing, as discussed in detail in the next subsection. We may also consider the orthogonal-opposite condition to be highlights in directions inconsistent with shading (orthogonal to the shading). Therefore, the results are interpreted to mean that unnatural highlights placed in a direction inconsistent with shading decrease or do not alter searching time depending on the spatial organization of the highlights. This suggests that the inconsistent highlights may facilitate shading processing and do not suppress it.</ce:para>
                  </ce:section>
                  <ce:section role="discussion" id="s0055" view="all">
                     <ce:label>3.3</ce:label>
                     <ce:section-title id="st070">Discussion</ce:section-title>
                     <ce:para id="p0120" view="all">Similar reaction times for the consistent and inconsistent conditions may raise the question of whether low-level differences in images between a target and a distractor underlie the perception. Our results showed the dependence of reaction time on the direction of highlights (bright spots) with respect to the shading gradient; the highlights in the directions parallel to the shading gradient evoked facilitation (the consistent and inconsistent conditions), but those orthogonal to the shading did not (the orthogonal and orthogonal-opposite conditions). As described in Section <ce:cross-ref refid="s0010" id="c0120">2</ce:cross-ref>, in the shading condition the dependence of reaction time on the direction of shading has been considered to be evidence of shading processing (e.g., <ce:cross-refs refid="b0100 b0010 b0055" id="r0025">Ramachandran, 1988; Aks &amp; Enns, 1992; Kleffner &amp; Ramachandran, 1992</ce:cross-refs>). Similarly, we consider the dependence on the direction of highlights with respect to shading to be evidence of highlight processing. If the facilitation originated from the low-level features, which were the differences in the location of highlights, dependence on the direction of highlights should not be observed. Low-level differences in the images cannot account for this dependence on the direction of highlights. Furthermore, we examined quantitatively whether the reaction time depends on the difference in luminance between a target and a distractor. The consistent and inconsistent conditions showed the greatest and least absolute magnitudes of the differences in luminance among the five conditions, respectively, while both conditions showed the shortest reaction times among the five. The difference in luminance between a target and a distractor cannot account for the reaction time.</ce:para>
                     <ce:para id="p0125" view="all">The luminance contrast varied with the addition of highlights and their directions with respect to shading. Because the contrast could affect the reaction time in searching, we examined whether the reaction time decreases as the contrast increases. The Michelson contrast of highlights with respect to the background outside the sphere (background contrast) and that with respect to the immediate surround within the sphere (immediate contrast) are shown in <ce:cross-ref refid="t0005" id="c0125">Table 1</ce:cross-ref>
                        <ce:float-anchor refid="t0005"/> (the second and third columns). The immediate surround was defined by the immediate-outside pixels of the circle whose center and radius were given by the brightest point and the most prominent point of inflection around the highlight, respectively. Because the background was black (0) and the highlight was white (1), the background contrast for all stimulus types with highlights was one. The immediate contrast varied depending on the location of highlights with respect to shading. Although the strong highlight condition had the smallest contrast (0.14) and the inconsistent highlight had the largest contrast (0.47), these conditions share the shortest reaction time (44–46<ce:hsp sp="0.25"/>ms shorter than for shading). The immediate contrast of the highlight-only condition and that of the strong highlight condition was the same (0.14), but the reaction time differed by 768<ce:hsp sp="0.25"/>ms. These results indicate that the facilitation in reaction time was independent of the luminance contrast of the highlights.</ce:para>
                     <ce:para id="p0130" view="all">An addition of naturalistic highlights (in the highlight condition) evokes the perception of glossiness. With unnatural highlights (in the inconsistent, orthogonal, and orthogonal-opposite conditions), a surface might appear glossy but the bright region could instead appear as a change in albedo on a matte surface. To examine the appearance of the stimuli, whether they appeared glossy or matte, we performed an additional experiment with the same stimuli and procedure except for the instruction, as per the details shown in <ce:cross-ref refid="s0125" id="c0130">Supplement 3</ce:cross-ref>. We presented all types of stimuli, one at a time in a random order with repetitions, and asked participants to judge whether the stimuli appeared glossy or matte in a two-alternative forced choice paradigm. The participants perceived glossy surfaces in the strong highlight, inconsistent, and orthogonal conditions. Although these stimuli sometimes may not appear specular on a print, or for a long duration, they appeared specular under the conditions of the experiment for the participants. It should be noted that the result of this experiment does not show the degree of perceptual glossiness; rather, it shows the subjective two-alternative judgment of either gloss or matte. It is natural to expect that the participants perceived distinct degrees of glossiness depending on the highlight conditions. Investigation into the relation between the reaction time and the degree of glossiness may further advance the understanding of highlight processing.</ce:para>
                     <ce:para id="p0135" view="all">Although some psychophysical studies have reported that the perception of glossiness might depend on the skewness of a luminance histogram (e.g., <ce:cross-ref refid="b0070" id="c0135">Motoyoshi et al., 2007</ce:cross-ref>), recent studies have reported the contrary evidence (e.g., <ce:cross-refs refid="b0015 b0065" id="r0030">Anderson &amp; Kim, 2009; Marlow, Kim, &amp; Anderson, 2011</ce:cross-refs>). To examine whether the skewness accounts for the facilitation in the present highlight conditions, we plotted luminance histograms (<ce:cross-ref refid="f0025" id="c0140">Fig. 5</ce:cross-ref>
                        <ce:float-anchor refid="f0025"/>
                        <ce:float-anchor refid="f0030"/>
                        <ce:float-anchor refid="f0035"/>) and computed their skewness. The histogram of the consistent highlight condition has a longer tail than that of the shading condition, as expected, but this is not true for the inconsistent highlight condition. The skewness values of the shading, consistent, and inconsistent highlight conditions were 3.64, 5.22, and 3.15, respectively. The stimuli of consistent and inconsistent highlights evoked similar reaction times that were shorter than for the stimulus of shading, as described in the previous subsection. These results indicate that luminance skewness does not account for the facilitation in searching time.</ce:para>
                     <ce:para id="p0140" view="all">Note that our focus on inconsistent and orthogonal-opposite conditions is to test the highlights as a low-level feature of images, with our aim being to understand the integration of highlights with shading processing. Our results showed that when a bright region was placed consistently with shading, the addition of the bright region facilitated detection in reaction time. The inconsistent stimuli could distract/slow the perception, but surprisingly, they did not suppress detection. The result indicates the robustness of shading processing in the integration of highlight processing. Specifically, the visual system is robust to the location of highlight with respect to shading. A bright region at the correct location appears to facilitate shading processing, but that at an incorrect location does not suppress the shading processing. This may be natural from an ecological viewpoint because the visual system may not be capable of computing the exact locations of highlights under natural illumination. As discussed in the previous section, we asked participants to detect a target. Therefore, it is unclear what was changed perceptually by the difference in the location of a bright region. A further study to link the detection and the perception of shape, depth, surface appearance and other features would help us understand the neural mechanisms underlying the facilitation.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0060" view="all">
                  <ce:label>4</ce:label>
                  <ce:section-title id="st075">Experiment 3</ce:section-title>
                  <ce:para id="p0145" view="all">We examined whether more physically plausible highlights, specifically image-based highlights, facilitate reaction time in the same manner as those under the simple highlights used in the previous experiments. As described in the previous sections, the addition of simple highlights to shading facilitated the search, and this result held even when the lighting directions of the shading and highlights were inconsistent. However, the highlights generated by a Phong model were considered simple, and the perception of shape may be degraded compared to the case of realistic highlights in which the shape of the light source is visible on an object (<ce:cross-ref refid="b0005" id="c0145">Adelson, 2008</ce:cross-ref>). In this section, we examined whether facilitation in the search is valid for image-based highlights. This experiment may also provide the basis for a discussion on the consistency of lighting directions between shading and highlights, because the realistic highlights may lower ambiguity in the direction of lighting.</ce:para>
                  <ce:section id="s0065" view="all">
                     <ce:label>4.1</ce:label>
                     <ce:section-title id="st080">Method</ce:section-title>
                     <ce:para id="p0150" view="all">The stimuli were identical to those in Experiment 1, except for the generation of shading and highlights. We used a single light-source for shading identical to that described in the previous sections, but with a more physically plausible rendering method (Ward model in RADIANCE (<ce:cross-ref refid="b0115" id="c0150">Ward, 1994</ce:cross-ref>)). The luminance of the shading ranged between 10.3 and 44.8<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup> (<ce:italic>specularity</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0 and <ce:italic>roughness</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0 for <ce:italic>plastic</ce:italic> in RADIANCE). To generate more physically plausible highlights than those used in the previous sections, we used the image-based highlights in which the spatial extent (shape) of a highlight was visible. Specifically, we took digital photos of a spherical mirror (environmental photos) and combined them with the sphere rendered with RADIANCE. We took digital photos of a mirror sphere under a variety of real lightings. The circular region of the photo corresponding to the mirror sphere was trimmed and binarized at a threshold. The bright regions were whitened and the rest of the region within the sphere was blackened. The direction of the light source for these highlights was defined as the direction of the center of gravity of the highlight region. Examples of the highlights are shown in <ce:cross-ref refid="f0030" id="c0155">Fig. 6</ce:cross-ref>(A). Among tens of environmental photos, we chose 10 highlights by visual inspection to ensure variety. Examples of the spheres are shown in <ce:cross-ref refid="f0030" id="c0160">Fig. 6</ce:cross-ref>(B). Note that the background was set to the mid-gray that is the mean luminance of the stimuli (35.0<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>). We also tested this with a black background and compared the results. The results of the two cases were identical in a statistical analysis (data shown in <ce:cross-ref refid="s0125" id="c0165">Supplement 4</ce:cross-ref>). We also tested more physically-plausible stimuli, in which both shading and highlights were rendered based on the environmental photos (Image Based Lighting (IBL) in RADIANCE). In this case, the reflectance properties were controlled (<ce:italic>specularity</ce:italic>
                        <ce:hsp sp="0.25"/>
                        <ce:italic>=</ce:italic>
                        <ce:hsp sp="0.25"/>0 and 1.0 for shading and highlight, respectively, in RADIANCE) to generate the four conditions (highlight only, shading, inconsistent highlight, and highlight). The result of the statistical analysis was identical to that presented in this section. In the present experiment, we chose not to use IBL in order to ensure identical shading among the stimuli. The shading from IBL depended on the environmental photo. The experimental procedures were identical to those used in Experiment 1 except for the total number of stimuli presented, because the number of conditions was different. Six participants completed the experiment. They had not participated in the previous experiments, but they shared the same conditions as Experiment 1.</ce:para>
                  </ce:section>
                  <ce:section role="results" id="s0070" view="all">
                     <ce:label>4.2</ce:label>
                     <ce:section-title id="st085">Results</ce:section-title>
                     <ce:para id="p0155" view="all">We measured the searching time for stimuli with image-based highlights. <ce:cross-ref refid="f0035" id="c0170">Fig. 7</ce:cross-ref> shows the mean reaction time for all participants. The results for the shading and inconsistent highlight conditions appear similar, and the searching times are longer than those for the highlight condition. A three-way ANOVA showed significant differences for highlight conditions (shading, highlight, and inconsistent highlight), lighting direction, and participants (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01 for all three factors). This result suggests a shorter reaction time for the highlight condition, and its dependence on the lighting direction. The interactions were also significant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01 for all three interactions), indicating the dependence of facilitation on lighting direction.</ce:para>
                     <ce:para id="p0160" view="all">The mean difference in reaction time between shading and highlight was 72<ce:hsp sp="0.25"/>ms, which is significant (pairwise <ce:italic>t</ce:italic>-test, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01). This result indicates that the image-based highlights facilitate shading processing, which is consistent with the results of the simple highlights described in the previous sections. The mean difference in reaction time between shading and inconsistent highlight was 8<ce:hsp sp="0.25"/>ms, which is insignificant (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0.35). This result indicates that inconsistent highlights did not alter perceptions in comparison with shading, which differs from the results with the simple highlights in the previous section. These results indicate that the stimuli with image-based highlights evoked facilitation, but the stimuli with the light sources that were inconsistent between shading and highlights did not alter the perception. This suggests that image-based highlights may facilitate shading processing, depending on the spatial organization of highlights, and they do not suppress perception.</ce:para>
                  </ce:section>
                  <ce:section role="discussion" id="s0075" view="all">
                     <ce:label>4.3</ce:label>
                     <ce:section-title id="st090">Discussion</ce:section-title>
                     <ce:para id="p0165" view="all">Facilitation by ordinary highlights was observed in both simple and image-based highlights; however, facilitation by the highlights inconsistent with shading was observed only with simple highlights. It is possible that image-based highlights are more effective for estimating lighting direction, so that contradiction in lighting directions between shading and highlights prevents facilitation. Realistic highlights are considered to evoke better perception of shape (<ce:cross-ref refid="b0005" id="c0175">Adelson, 2008</ce:cross-ref>). Our data showed that the mean searching time for the highlight-only condition ranged between 1.05 and 1.2<ce:hsp sp="0.25"/>s, which was about 40% to 70% shorter than that for the simple highlights used in Experiment 2. This result is consistent with the notion of the better perception of shape with realistic highlights (<ce:cross-ref refid="b0005" id="c0180">Adelson, 2008</ce:cross-ref>).</ce:para>
                     <ce:para id="p0170" view="all">The reaction time for solely image-based highlights was 30% to 100% longer than that for shading, but the range of 1.05–1.2<ce:hsp sp="0.25"/>s suggests that only highlights may evoke a pre-attentive pop-out, in contrast with the previous sections. The reaction time shows a flattened “V” shape, somewhat similar to that in the shading condition, with significant dependence on the lighting direction (one-way ANOVA, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01). This result suggests that the pattern of realistic highlights evokes shape perception similar to shading in quality, but with more processing time. It should be noted that the longer reaction time for the highlight-only condition compared with the shading condition (pairwise <ce:italic>t</ce:italic>-test, <ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.01) and the facilitation by the addition of highlights suggest the nonlinearity of the cue integration, as reported in the previous sections.</ce:para>
                     <ce:para id="p0175" view="all">It may be questioned whether the stimuli with inconsistent highlights appeared glossy. In other words, shading could be perceived as a change in albedo with dark at the top and bright at the bottom, or vice versa. The reaction times for the inconsistent condition show the dependence of reaction time on lighting direction to be similar to that in the shading and highlight conditions. This dependency is considered to be evidence that participants perceived the luminance gradient as shading. If the participants did not perceive shading, and low-level features of the images such as the difference in location of bright regions evoked detection, the reaction times should be independent of the direction of lighting and greater than those in the shading condition.</ce:para>
                     <ce:para id="p0180" view="all">To examine the appearance of the stimuli whether they appeared glossy or matte we performed an additional experiment with the same methods as in the previous section (see <ce:cross-ref refid="s0125" id="c0185">Supplement 3</ce:cross-ref> for details). The results indicated that the participants perceived glossy surfaces with the highlight, inconsistent highlight, and highlight-only conditions. As noted in <ce:cross-ref refid="s0125" id="c0190">Section 3.2</ce:cross-ref>, the result of this supplemental experiment does not show the degree of perceptual glossiness; rather, it shows the subjective two-alternative judgment of either gloss or matte. Investigation into the relation between the reaction time and the degree of glossiness is expected to further advance the understanding of highlight processing. The addition of highlights altered the luminance contrast, as discussed in Experiment 2. We examined whether the reaction time decreases as the contrast increases using the same methods as in the previous section. The results indicated that the reaction time was independent of the luminance contrast, as shown in <ce:cross-ref refid="t0010" id="c0195">Table 2</ce:cross-ref>
                        <ce:float-anchor refid="t0010"/>.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0080" view="all">
                  <ce:label>5</ce:label>
                  <ce:section-title id="st095">Experiment 4</ce:section-title>
                  <ce:para id="p0185" view="all">The experiments thus far have shown facilitation of reaction time caused by the addition of highlights to shading. Although the paradigm used has been thought to be the processing of shape-from-shading, it is not clear what caused the facilitation of reaction time. To examine whether the highlights have a facilitative function in the discrimination of depth, we conducted experiments with a depth discrimination task. We used random surfaces to achieve appropriate incongruence between shading and highlight, similar to <ce:cross-ref refid="b0095" id="c0200">Phillips et al. (1997)</ce:cross-ref> and others (<ce:cross-refs refid="b0090 b0065" id="r0035">Norman, Todd, &amp; Orban, 2004; Marlow, Kim, &amp; Anderson, 2011</ce:cross-refs>). If the correct response rate increases when highlights are added to shading, this indicates that highlights work, as they facilitate the perception of depth. If the correct response rate does not decrease even when the lighting directions are inconsistent, this further suggests that highlights do not work, as they suppress perception, consistent with the results of the searching experiments.</ce:para>
                  <ce:section id="s0085" view="all">
                     <ce:label>5.1</ce:label>
                     <ce:section-title id="st100">Method</ce:section-title>
                     <ce:section id="s0090" view="all">
                        <ce:label>5.1.1</ce:label>
                        <ce:section-title id="st105">Stimuli</ce:section-title>
                        <ce:para id="p0190" view="all">Random surfaces were generated from a Uniform-B-Spline surface with 8<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>8 knot vectors using OpenGL (gluNurbsSurface). The depth of the knots was randomized but limited so that neither shadow nor self-occlusion appeared. We generated 50 types of randomized terrain. The properties of lighting and surface were identical to those in Experiment 2 except for the limitations on the lighting directions. The lighting direction for shading was fixed to top-left (tilt<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>+45°; slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>51°) and that for highlights was limited to top-left (tilt<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>+45°; slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>51°), top-right (tilt<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>−45°; slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>51°), bottom-left (tilt<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>135°; slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>51°), bottom-right (tilt<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>−135°; slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>51°), and the viewer’s direction (slant<ce:hsp sp="0.25"/>=<ce:hsp sp="0.25"/>0°). As described in Experiment 2, we used two independent light sources, one for shading and the other for highlighting. When the lighting direction for highlighting was top-left, rendered shading and highlights were consistent and considered natural in terms of lighting directions. For the other cases, shading and highlights were inconsistent and unnatural. Examples of the stimuli are shown in <ce:cross-ref refid="f0040" id="c0205">Fig. 8</ce:cross-ref>
                           <ce:float-anchor refid="f0040"/>. The luminance of the stimuli ranged between 10.3 and 55.6<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>. Stimuli were placed 110<ce:hsp sp="0.25"/>cm in front of the participants so as to ensure 5<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>5° in the visual angle. The spatial frequency of the surface bumpiness was limited to 0.7<ce:hsp sp="0.25"/>cycles/degree and below.</ce:para>
                     </ce:section>
                     <ce:section id="s0095" view="all">
                        <ce:label>5.1.2</ce:label>
                        <ce:section-title id="st110">Procedure and participants</ce:section-title>
                        <ce:para id="p0195" view="all">The experiments were conducted in a dark room without any light except the monitor. A blank screen was presented for 500<ce:hsp sp="0.25"/>ms, followed by a random-surface stimulus on which two yellow dots (target) and one red dot were placed (0.1°<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>0.1° in visual angle, 45<ce:hsp sp="0.25"/>cd/m<ce:sup loc="post">2</ce:sup>). The initial locations of the yellow and red dots were randomly chosen from the locations of 8<ce:hsp sp="0.25"/>×<ce:hsp sp="0.25"/>8 knots without an overlap. Participants were asked to compare the depth of the two locations where yellow dots indicated. They were asked to report which location appeared nearer to them in comparison with the other location, by moving the red dot to the yellow dot on the nearer location using arrow keys (two in horizontal directions and two in vertical directions). When a specified key (distinct from the arrows) was pressed, the location of the red dot overlapped on a yellow dot was recorded. Then, the next mask was presented.</ce:para>
                        <ce:para id="p0200" view="all">Each participant was presented with 660 stimuli. We recorded the responses from 600 stimuli (six lighting conditions) and discarded the other 60 responses that were shown at the beginning of the experiment, and when the lighting conditions changed. The participants completed 50 trials for each lighting condition, resulting in 330 trials in a row (one set). The participants completed two sets with a break in between. The order of the lighting condition and surface terrain were randomized. Because yellow dots were randomly placed anywhere on a terrain, the result reflected the perception of depth for overall terrains. Nine participants (six males and three females) participated in the experiment. They had not participated in the previous experiments, but they shared the same conditions as Experiment 1.</ce:para>
                     </ce:section>
                  </ce:section>
                  <ce:section role="results" id="s0100" view="all">
                     <ce:label>5.2</ce:label>
                     <ce:section-title id="st115">Results</ce:section-title>
                     <ce:para id="p0205" view="all">We measured the correct response rate in the discrimination of depth to examine whether highlights facilitate the perception of depth from shading. <ce:cross-ref refid="f0045" id="c0210">Fig. 9</ce:cross-ref>
                        <ce:float-anchor refid="f0045"/> shows the mean correct response rate among all participants for the six lighting conditions. The stimuli with no highlights (shading condition) yielded a 55% correct response rate, indicating the participants’ difficulty in perceiving depth in the shading stimuli. The addition of highlights increased the correct response rates for all highlight conditions. Pairwise <ce:italic>t</ce:italic>-tests between the shading condition and each of the highlight conditions showed significant differences (<ce:italic>p</ce:italic>
                        <ce:hsp sp="0.25"/>&lt;<ce:hsp sp="0.25"/>0.02). This result showed the facilitation of depth discrimination caused by the addition of highlights. Note that the facilitation was observed for all inconsistent directions of light in the depth discrimination, while in searching, facilitation was observed only in the opposite direction (Experiment 2). The present experiment showed facilitation by highlights in depth discrimination even when their lighting directions are inconsistent with those of the shading.</ce:para>
                  </ce:section>
                  <ce:section role="discussion" id="s0105" view="all">
                     <ce:label>5.3</ce:label>
                     <ce:section-title id="st120">Discussion</ce:section-title>
                     <ce:para id="p0210" view="all">The present results showed facilitation by highlights in depth discrimination even when their lighting directions deviated from those of the shading. The results of the discrimination and the search agree, in that the inconsistent lighting directions facilitate, and do not suppress perception. However, in Experiment 2, facilitation was limited to the opposite direction of lighting (inconsistent condition). The lighting from the lateral directions (orthogonal-opposite condition) did not affect searching time. The result of the discrimination showed similar correct rates among the bottom-left, top-right (the orthogonal lightings with respect to the lighting for shading), and bottom-right conditions (the opposite lighting). This deviation might be originated from a difference in complexity of shape; a sphere and a random terrain, and might be related to a difference in the appearance of surfaces. Further investigation is required to understand the cause of the divergence. The result of this experiment shows direct evidence for the facilitation of depth perception by the addition of highlights to shading. This result supports that the facilitation of reaction time in searching was relevant to the perception of depth.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section role="discussion" id="s0110" view="all">
                  <ce:label>6</ce:label>
                  <ce:section-title id="st125">General discussion</ce:section-title>
                  <ce:para id="p0215" view="all">We investigated whether specular highlights facilitate the perception of shape from shading in a searching paradigm and how highlights interact with shading to facilitate perception. Our results indicated that stimuli containing highlights led to shorter searching time with the dependence on light-source direction, suggesting that highlights work to facilitate shading processing. To examine how highlight processing interacts with shading processing, we tested unnatural stimuli whose lighting directions for shading and highlights are inconsistent. The results indicated that unnatural highlights placed in a direction inconsistent with shading decrease or do not alter searching time, suggesting that they may facilitate, but do not suppress shading processing. With the image-based highlights, we observed facilitation with consistent lighting but no change with inconsistent highlights. Finally, we examined whether highlights facilitate, but do not suppress, the perception of depth in a discrimination paradigm. The results showed that the correct discrimination rate increases when highlights are added to shading, indicating facilitation in the perception of depth. The results showed the facilitation even when their lighting directions were inconsistent. These results indicate that specular highlights work to facilitate shading processing and do not suppress it, even if highlights are placed in a direction inconsistent with shading.</ce:para>
                  <ce:para id="p0220" view="all">
                     <ce:cross-ref refid="b0020" id="c0215">Bülthoff (1991)</ce:cross-ref> reported that shading and addition of highlights lead to under- and overestimation of depth, respectively, in comparison with stereo-defined depth. Yet, because the data in that study showed accuracy in depth perception, a direct comparison with our experiment may be inappropriate. However, our results for searching and discrimination appear to be consistent with Bülthoff’s report in terms of the facilitation of perception in that the addition of highlights led to a shorter reaction time and a higher correct rate compared with those from shading. Further, Büelthoff reported that the addition of texture to shading has a facilitative function. Even random textures show this facilitation (<ce:cross-ref refid="b0105" id="c0220">Sakai, Narushima, &amp; Aoki, 2006</ce:cross-ref>). It would be interesting to examine further the integration of highlights with other cues.</ce:para>
                  <ce:para id="p0225" view="all">Some psychophysical studies have reported that specular highlights do not facilitate the perception of detailed structure of a 3D shape. The perception of detailed shapes (surface normals) that was measured by a needle probe depended on the bidirectional reflectance distribution function (BRDF) and lighting, but not on specular highlights and surface glossiness (<ce:cross-refs refid="b0050 b0080" id="r0040">Khang, Koenderink, &amp; Kappers, 2007; Nefs, Koenderink, &amp; Kappers, 2006</ce:cross-refs>). This deviation may naturally come from the difference in measurement: the detection of local surface orientation and the pop-out. It may also be possible, at least in part, that different levels of cortical processing are responsible, that is, a pre-attentive level (early-to-intermediate cortical levels) for pop-out, and a conscious, associative level (higher cortical level) for needle probe measurement.</ce:para>
                  <ce:para id="p0230" view="all">It would be interesting to consider how the constraint on light source works in the inconsistent condition. The visual system appears to use a “unique light-source” constraint for shape from shading that is considered to have priority over the top-light constraint (<ce:cross-ref refid="b0055" id="c0225">Kleffner &amp; Ramachandran, 1992</ce:cross-ref>). Because the inconsistent highlight condition does not have a unique light source, it would be interesting to consider whether the unique light-source constraint holds between shading and highlights. If the perception were suppressed, this would suggest that the visual system assumed a common light source for the shading and highlight, so that two cues would indicate contradictory shapes. On the other hand, if the perception were facilitated, this would suggest an assumption of distinct light sources for shading and highlights so that the two cues would indicate a consistent shape. Our results showed facilitation of perception, thereby supporting the latter case. However, facilitation by inconsistent highlights was not observed for the imaged-based highlights. It is possible that highlight processing is rather insensitive to the direction of the light source, compared with shape from shading, unless the shape of highlights is visible so that the lighting direction is apparent. This idea appears plausible because the exact location of highlights is not crucial in depth discrimination, as shown in Experiment 4. This idea is consistent with our experience of placing a pointillé on a picture. A painter may place white paint without precision, but it often yields vivid depth. Recent computational studies have provided some insightful evidence for the computation of depth with regard to the robustness in lighting directions. <ce:cross-ref refid="b0060" id="c0230">Kunsberg and Zucker (2013)</ce:cross-ref> have suggested that the shape-from-shading problem could be computed from the second derivatives of brightness that are independent of lighting direction. <ce:cross-ref refid="b0035" id="c0235">Chen, Goesele, and Seidel (2006)</ce:cross-ref> have also reported that the mesostructure of a surface could be computed from a dense specularity field without other information. It would be interesting to investigate whether these computations are relevant to the cortical processing.</ce:para>
                  <ce:para id="p0235" view="all">Recent psychophysical and physiological studies have extensively investigated the perception of glossiness (e.g., <ce:cross-ref refid="b0085" id="c0240">Nishio, Goda, &amp; Komatsu, 2012</ce:cross-ref>). It is interesting to consider how the perception of glossiness relates to that of depth. Although the skew of luminance histogram has been considered a good measure for the perception of surface glossiness (<ce:cross-ref refid="b0070" id="c0245">Motoyoshi et al., 2007</ce:cross-ref>), this skewness does not account for facilitation, as reported in Experiment 2. <ce:cross-ref refid="b0065" id="c0250">Marlow, Kim, and Anderson’s (2011)</ce:cross-ref> psychophysical study reported that spatial congruence between shading and highlights is crucial for the perception of glossiness. Our stimuli with highlights for which the lighting was consistent with shading are considered congruent, and those with inconsistent highlights are not. Our results showed that consistent highlights facilitated perception, whereas the inconsistent lighting did not—specifically, the lateral lighting in Experiment 2 and the lighting opposite to that of shading in Experiment 3. This agreement with the perception of glossiness suggests that the congruence may also be crucial in the perception of depth. Another study has reported that the reflectance of the surrounding environment on a specular object, specifically the distortion, is a crucial cue for the perception of shape (<ce:cross-ref refid="b0040" id="c0255">Fleming, Torralba, &amp; Adelson, 2004</ce:cross-ref>). We could predict from their results that the spatial congruence of highlights and shading is more crucial if a surface is more specular. With more specular highlights in Experiment 3, the inconsistent highlights did not evoke facilitation, in contrast to the less-specular highlights used in Experiment 2. This result is consistent with the effects of specular reflectance in the perception of shape. As noted in the previous sections, an investigation on the link between the surface appearance and the searching time would be expected to further advance the understanding of highlight processing.</ce:para>
               </ce:section>
               <ce:section id="s0115" view="all">
                  <ce:label>7</ce:label>
                  <ce:section-title id="st130">Conclusion</ce:section-title>
                  <ce:para id="p0240" view="all">We investigated whether specular highlights facilitate the perception of shape from shading in a searching paradigm, and how highlights interact with shading to facilitate this perception. We utilized the light-direction dependence of searching time as an indication of shading processing, in which top lights yield shorter searching times than lateral lights. Our psychophysical experiments showed light-direction dependence with less searching time for the combination of shading and highlights, suggesting that specular highlights work so as to facilitate shading processing. To examine further how the highlight processing works with shading processing, we tested unnatural stimuli whose lighting directions for shading and highlights were inconsistent. The results did not show an increase in searching time, suggesting that inconsistent highlights do not suppress shading processing. Additional experiments showed the same results for the imaged-based highlights. Finally, to confirm whether the highlights work to facilitate or suppress the perception in the discrimination of depth rather than searching, we conducted a depth discrimination experiment using random surfaces. The results showed facilitation in the discrimination when highlights are added to shading. These results indicated that specular highlights work to facilitate shading processing and do not suppress it, even when the light sources are inconsistent between highlights and shading. The results also elucidated the lighting constraints of the visual system.</ce:para>
               </ce:section>
            </ce:sections>
            <ce:acknowledgment id="ak005" view="all">
               <ce:section-title id="st135">Acknowledgments</ce:section-title>
               <ce:para id="p0245" view="all">This work was supported by Grant-in-Aids from the <ce:grant-sponsor xlink:type="simple" id="gp005" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">Ministry of Education, Culture, Sports and Technology of Japan</ce:grant-sponsor> (<ce:grant-number refid="gp005">25135704</ce:grant-number> (Shitsukan)) and <ce:grant-sponsor sponsor-id="http://dx.doi.org/10.13039/501100001691" xlink:type="simple" id="gp010" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">JSPS</ce:grant-sponsor> KAKENHI (<ce:grant-number refid="gp010">23135503</ce:grant-number> and <ce:grant-number refid="gp010">26280047</ce:grant-number>).</ce:para>
            </ce:acknowledgment>
            <ce:appendices view="all">
               <ce:section view="compact-standard" id="s0120">
                  <ce:label>Appendix A</ce:label>
                  <ce:section-title id="st140">Supplementary data</ce:section-title>
                  <ce:para id="p0250" view="all">Supplementary data associated with this article can be found, in the online version, at <ce:inter-ref xlink:href="doi:10.1016/j.visres.2015.05.001" xlink:type="simple" id="ir005">http://dx.doi.org/10.1016/j.visres.2015.05.001</ce:inter-ref>.</ce:para>
               </ce:section>
               <ce:section view="extended" id="s0125">
                  <ce:label>Appendix A</ce:label>
                  <ce:section-title id="st145">Supplementary data</ce:section-title>
                  <ce:para id="p0255" view="all">
                     <ce:display>
                        <ce:e-component id="m0005">
                           <ce:label>Supplementary video 1</ce:label>
                           <ce:link locator="mmc1"/>
                        </ce:e-component>
                     </ce:display>
                     <ce:display>
                        <ce:e-component id="m0010">
                           <ce:label>Supplementary video 2</ce:label>
                           <ce:link locator="mmc2"/>
                        </ce:e-component>
                     </ce:display>
                     <ce:display>
                        <ce:e-component id="m0015">
                           <ce:label>Supplementary video 3</ce:label>
                           <ce:link locator="mmc3"/>
                        </ce:e-component>
                     </ce:display>
                     <ce:display>
                        <ce:e-component id="m0020">
                           <ce:label>Supplementary video 4</ce:label>
                           <ce:link locator="mmc4"/>
                        </ce:e-component>
                     </ce:display>
                     <ce:display>
                        <ce:e-component id="m0025">
                           <ce:label>Supplementary video 5</ce:label>
                           <ce:link locator="mmc5"/>
                        </ce:e-component>
                     </ce:display>
                     <ce:display>
                        <ce:e-component id="m0030">
                           <ce:label>Supplementary data 6</ce:label>
                           <ce:caption id="cn0075">
                              <ce:simple-para id="sp0015" view="all">This supplementary data contains figures.</ce:simple-para>
                           </ce:caption>
                           <ce:link locator="mmc6"/>
                        </ce:e-component>
                     </ce:display>
                  </ce:para>
               </ce:section>
            </ce:appendices>
         </body>
         <tail view="all">
            <ce:bibliography id="bi005" view="all">
               <ce:section-title id="st150">References</ce:section-title>
               <ce:bibliography-sec id="bs005" view="all">
                  <ce:bib-reference id="b0005">
                     <ce:label>Adelson, 2008</ce:label>
                     <sb:reference id="h0005">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>E.H.</ce:given-name>
                                 <ce:surname>Adelson</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Image statistics and surface perception</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Proceedings of the SPIE, Human Vision and Electronic Imaging XIII</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>6809</sb:volume-nr>
                              </sb:series>
                              <sb:date>2008</sb:date>
                           </sb:issue>
                        </sb:host>
                        <sb:comment>680602-680602-9</sb:comment>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0010">
                     <ce:label>Aks and Enns, 1992</ce:label>
                     <sb:reference id="h0010">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>D.</ce:given-name>
                                 <ce:surname>Aks</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Enns</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Visual search for direction of shading is influenced by apparent depth</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Perception and Psychophysics</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>52</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>1</sb:issue-nr>
                              <sb:date>1992</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>63</sb:first-page>
                              <sb:last-page>74</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0015">
                     <ce:label>Anderson and Kim, 2009</ce:label>
                     <sb:reference id="h0015">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>B.L.</ce:given-name>
                                 <ce:surname>Anderson</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Kim</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Image statistics do not explain the perception of gloss and lightness</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>9</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>11–10</sb:issue-nr>
                              <sb:date>2009</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>17</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0020">
                     <ce:label>Bülthoff, 1991</ce:label>
                     <sb:reference id="h0020">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>H.H.</ce:given-name>
                                 <ce:surname>Bülthoff</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Shape from X: Psychophysics and computation</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:edited-book>
                              <sb:editors>
                                 <sb:editor>
                                    <ce:given-name>M.S.</ce:given-name>
                                    <ce:surname>Landy</ce:surname>
                                 </sb:editor>
                                 <sb:editor>
                                    <ce:given-name>J.A.</ce:given-name>
                                    <ce:surname>Movshon</ce:surname>
                                 </sb:editor>
                              </sb:editors>
                              <sb:title>
                                 <sb:maintitle>Computational models of visual processing</sb:maintitle>
                              </sb:title>
                              <sb:date>1991</sb:date>
                              <sb:publisher>
                                 <sb:name>MIT Press</sb:name>
                                 <sb:location>London, England</sb:location>
                              </sb:publisher>
                           </sb:edited-book>
                           <sb:pages>
                              <sb:first-page>305</sb:first-page>
                              <sb:last-page>330</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0025">
                     <ce:label>Chacón, 2004</ce:label>
                     <sb:reference id="h0025">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Chacón</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Perceived contrast explains asymmetries in visual-search tasks with shaded stimuli</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Perception</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>33</sb:volume-nr>
                              </sb:series>
                              <sb:date>2004</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1499</sb:first-page>
                              <sb:last-page>1509</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0030">
                     <ce:label>Champion and Adams, 2007</ce:label>
                     <sb:reference id="h0030">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>R.A.</ce:given-name>
                                 <ce:surname>Champion</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>W.J.</ce:given-name>
                                 <ce:surname>Adams</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Modification of the convexity prior but not the light-from-above prior in visual search with shaded objects</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>7</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>13</sb:issue-nr>
                              <sb:date>2007</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>10</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0035">
                     <ce:label>Chen et al., 2006</ce:label>
                     <sb:reference id="h0035">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>T.</ce:given-name>
                                 <ce:surname>Chen</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Goesele</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.-P.</ce:given-name>
                                 <ce:surname>Seidel</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Mesostructure from specularity</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Proceedings of IEEE Computer Vision and Pattern Recognition</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>2</sb:volume-nr>
                              </sb:series>
                              <sb:date>2006</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1825</sb:first-page>
                              <sb:last-page>1832</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0040">
                     <ce:label>Fleming et al., 2004</ce:label>
                     <sb:reference id="h0040">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>R.W.</ce:given-name>
                                 <ce:surname>Fleming</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Torralba</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>E.H.</ce:given-name>
                                 <ce:surname>Adelson</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Specular reflections and the perception of shape</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>4</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>9</sb:issue-nr>
                              <sb:date>2004</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>798</sb:first-page>
                              <sb:last-page>820</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0045">
                     <ce:label>Kawabe and Miura, 2004</ce:label>
                     <sb:reference id="h0045">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>T.</ce:given-name>
                                 <ce:surname>Kawabe</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Miura</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Perceptual grouping in shape from shading</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Perception</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>33</sb:volume-nr>
                              </sb:series>
                              <sb:date>2004</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>601</sb:first-page>
                              <sb:last-page>614</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0050">
                     <ce:label>Khang et al., 2007</ce:label>
                     <sb:reference id="h0050">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>B.-G.</ce:given-name>
                                 <ce:surname>Khang</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.J.</ce:given-name>
                                 <ce:surname>Koenderink</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.M.</ce:given-name>
                                 <ce:surname>Kappers</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Shape from shading from images rendered with various surface types and light fields</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Perception</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>36</sb:volume-nr>
                              </sb:series>
                              <sb:date>2007</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1191</sb:first-page>
                              <sb:last-page>1213</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0055">
                     <ce:label>Kleffner and Ramachandran, 1992</ce:label>
                     <sb:reference id="h0055">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>D.</ce:given-name>
                                 <ce:surname>Kleffner</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>V.S.</ce:given-name>
                                 <ce:surname>Ramachandran</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>On the perception of shape from shading</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Perception &amp; Psychophysics</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>52</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>1</sb:issue-nr>
                              <sb:date>1992</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>18</sb:first-page>
                              <sb:last-page>36</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0060">
                     <ce:label>Kunsberg and Zucker, 2013</ce:label>
                     <ce:other-ref id="h0060">
                        <ce:textref>Kunsberg, B., &amp; Zucker, S. W. (2013). <ce:italic>Characterizing ambiguity in light source invariant shape from shading</ce:italic>. arXiv, 1306:5480v1 [cs.CV] 23 Jun 2013.</ce:textref>
                     </ce:other-ref>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0065">
                     <ce:label>Marlow et al., 2011</ce:label>
                     <sb:reference id="h0065">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>P.</ce:given-name>
                                 <ce:surname>Marlow</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Kim</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>B.L.</ce:given-name>
                                 <ce:surname>Anderson</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>The role of brightness and orientation congruence in the perception of surface gloss</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>11</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>9:16</sb:issue-nr>
                              <sb:date>2011</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>12</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0070">
                     <ce:label>Motoyoshi et al., 2007</ce:label>
                     <sb:reference id="h0070">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>I.</ce:given-name>
                                 <ce:surname>Motoyoshi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Nishida</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>L.</ce:given-name>
                                 <ce:surname>Sharan</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>E.</ce:given-name>
                                 <ce:surname>Adelson</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Image statistics and the perception of surface qualities</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Nature</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>447</sb:volume-nr>
                              </sb:series>
                              <sb:date>2007</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>206</sb:first-page>
                              <sb:last-page>209</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0075">
                     <ce:label>Nefs, 2008</ce:label>
                     <sb:reference id="h0075">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>H.T.</ce:given-name>
                                 <ce:surname>Nefs</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Three-dimensional object shape from shading and contour disparities</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>8</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>11</sb:issue-nr>
                              <sb:date>2008</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>16</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0080">
                     <ce:label>Nefs et al., 2006</ce:label>
                     <sb:reference id="h0080">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>H.T.</ce:given-name>
                                 <ce:surname>Nefs</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.J.</ce:given-name>
                                 <ce:surname>Koenderink</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.M.</ce:given-name>
                                 <ce:surname>Kappers</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Shape-from-shading for matte and glossy objects</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Acta Psychologica</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>121</sb:volume-nr>
                              </sb:series>
                              <sb:date>2006</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>297</sb:first-page>
                              <sb:last-page>316</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0085">
                     <ce:label>Nishio et al., 2012</ce:label>
                     <sb:reference id="h0085">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Nishio</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>N.</ce:given-name>
                                 <ce:surname>Goda</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.</ce:given-name>
                                 <ce:surname>Komatsu</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Neural selectivity and representation of gloss in the monkey inferior temporal cortex</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Neuroscience</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>32</sb:volume-nr>
                              </sb:series>
                              <sb:date>2012</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>10780</sb:first-page>
                              <sb:last-page>10793</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0090">
                     <ce:label>Norman et al., 2004</ce:label>
                     <sb:reference id="h0090">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>J.F.</ce:given-name>
                                 <ce:surname>Norman</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.T.</ce:given-name>
                                 <ce:surname>Todd</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>G.A.</ce:given-name>
                                 <ce:surname>Orban</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Perception of three-dimensional shape from specular highlights, deformations of shading, and other types of visual information</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Psychological Science</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>15</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>8</sb:issue-nr>
                              <sb:date>2004</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>565</sb:first-page>
                              <sb:last-page>570</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0095">
                     <ce:label>Phillips et al., 1997</ce:label>
                     <sb:reference id="h0095">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>F.</ce:given-name>
                                 <ce:surname>Phillips</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.T.</ce:given-name>
                                 <ce:surname>Todd</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.J.</ce:given-name>
                                 <ce:surname>Koenderink</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.M.L.</ce:given-name>
                                 <ce:surname>Kappers</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Perceptual localization of surface position</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Experimental Psychology: Human Perception and Performance</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>23</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>5</sb:issue-nr>
                              <sb:date>1997</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1481</sb:first-page>
                              <sb:last-page>1492</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0100">
                     <ce:label>Ramachandran, 1988</ce:label>
                     <sb:reference id="h0100">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>V.S.</ce:given-name>
                                 <ce:surname>Ramachandran</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Perception of shape from shading</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Nature</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>331</sb:volume-nr>
                              </sb:series>
                              <sb:date>1988</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>163</sb:first-page>
                              <sb:last-page>166</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0105">
                     <ce:label>Sakai et al., 2006</ce:label>
                     <sb:reference id="h0105">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Sakai</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Narushima</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>N.</ce:given-name>
                                 <ce:surname>Aoki</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Shape from shading – Facilitation by local contrast</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Optical Society of America A</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>23</sb:volume-nr>
                              </sb:series>
                              <sb:date>2006</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1805</sb:first-page>
                              <sb:last-page>1813</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0110">
                     <ce:label>Sun and Perona, 1998</ce:label>
                     <sb:reference id="h0110">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Sun</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>P.</ce:given-name>
                                 <ce:surname>Perona</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Where is the sun?</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Nature Neuroscience</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>1</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>3</sb:issue-nr>
                              <sb:date>1998</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>183</sb:first-page>
                              <sb:last-page>184</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0115">
                     <ce:label>Ward, 1994</ce:label>
                     <sb:reference id="h0115">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>G.J.</ce:given-name>
                                 <ce:surname>Ward</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>The RADIANCE lighting simulation and rendering system</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Computer Graphics</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>26</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>2</sb:issue-nr>
                              <sb:date>1994</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>265</sb:first-page>
                              <sb:last-page>272</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
                  <ce:bib-reference id="b0120">
                     <ce:label>Wijntjes et al., 2012</ce:label>
                     <sb:reference id="h0120">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>M.W.</ce:given-name>
                                 <ce:surname>Wijntjes</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Doerschner</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>Kucukoglu</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.C.</ce:given-name>
                                 <ce:surname>Pont</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Relative flattening between velvet and matte 3D shapes: Evidence for similar shape-from-shading computations</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Journal of Vision</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>12</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>1:2</sb:issue-nr>
                              <sb:date>2012</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>11</sb:last-page>
                           </sb:pages>
                        </sb:host>
                     </sb:reference>
                  </ce:bib-reference>
               </ce:bibliography-sec>
            </ce:bibliography>
         </tail>
      </article>
   </xocs:serial-item>
</xocs:doc></originalText></full-text-retrieval-response>